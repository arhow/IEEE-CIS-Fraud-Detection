{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  import sys\n",
    "# !{sys.executable} -m pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as sk_mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "class processutil:\n",
    "    def _str2class(s):\n",
    "        if s in globals() and isinstance(globals()[s], type):\n",
    "                return globals()[s]\n",
    "        if isinstance(eval(s), type):\n",
    "            return eval(s)\n",
    "        if callable(eval(s)):\n",
    "            return eval(s)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_pickle(f'{folder_path}/df_train3.gzde', compression='gzip')#.iloc[:100000,:]\n",
    "# df_test = pd.read_pickle(f'{folder_path}/df_test3.gzde', compression='gzip')#.iloc[:10000,:]\n",
    "df_train = df_train.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "# df_test = df_test.replace([np.inf, -np.inf], np.nan).fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train2 = pd.read_pickle(f'{folder_path}/df_train3.gzde', compression='gzip')#.iloc[:100000,:]\n",
    "# df_test2 = pd.read_pickle(f'{folder_path}/df_test3.gzde', compression='gzip')#.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_train = pd.DataFrame()\n",
    "df_oof_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_vae_train = pd.read_pickle(f'{folder_path}/oof_vae_train', compression='gzip')\n",
    "df_oof_vae_test = pd.read_pickle(f'{folder_path}/oof_vae_test', compression='gzip')\n",
    "df_oof_train = df_oof_vae_train\n",
    "df_oof_test = df_oof_vae_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_lgbm_train = pd.read_pickle(f'{folder_path}/oof_lgbm_train', compression='gzip')\n",
    "df_oof_lgbm_test = pd.read_pickle(f'{folder_path}/oof_lgbm_test', compression='gzip')\n",
    "df_oof_lgbm_test['predict'] = df_oof_lgbm_test[np.arange(8)].mean(axis=1)\n",
    "df_oof_train = pd.merge(df_oof_train, df_oof_lgbm_train[['TransactionID', 'predict']].rename(columns={'predict':'oof_lgbm'}), how='left', on='TransactionID')\n",
    "df_oof_test = pd.merge(df_oof_test, df_oof_lgbm_test[['TransactionID', 'predict']].rename(columns={'predict':'oof_lgbm'}), how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_xgbm_train = pd.read_pickle(f'{folder_path}/oof_xgbm_train', compression='gzip')\n",
    "df_oof_xgbm_test = pd.read_pickle(f'{folder_path}/oof_xgbm_test', compression='gzip')\n",
    "df_oof_xgbm_test['predict'] = df_oof_xgbm_test[np.arange(8)].mean(axis=1)\n",
    "df_oof_train = pd.merge(df_oof_train, df_oof_xgbm_train[['TransactionID', 'predict']].rename(columns={'predict':'oof_xgbm'}), how='left', on='TransactionID')\n",
    "df_oof_test = pd.merge(df_oof_test, df_oof_xgbm_test[['TransactionID', 'predict']].rename(columns={'predict':'oof_xgbm'}), how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_mlp_train = pd.read_pickle(f'{folder_path}/oof_mlp_train', compression='gzip')\n",
    "df_oof_mlp_test = pd.read_pickle(f'{folder_path}/oof_mlp_test', compression='gzip')\n",
    "df_oof_mlp_test['predict'] = df_oof_mlp_test[np.arange(8)].mean(axis=1)\n",
    "df_oof_train = pd.merge(df_oof_train, df_oof_mlp_train[['TransactionID', 'predict']].rename(columns={'predict':'oof_mlp'}), how='left', on='TransactionID')\n",
    "df_oof_test = pd.merge(df_oof_test, df_oof_mlp_test[['TransactionID', 'predict']].rename(columns={'predict':'oof_mlp'}), how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof_1dcnn_train = pd.read_pickle(f'{folder_path}/oof_1dcnn_train', compression='gzip')\n",
    "df_oof_1dcnn_test = pd.read_pickle(f'{folder_path}/oof_1dcnn_test', compression='gzip')\n",
    "# df_oof_1dcnn_test['predict'] = df_oof_1dcnn_test[np.arange(8)].mean(axis=1)\n",
    "df_oof_train = pd.merge(df_oof_train, df_oof_1dcnn_train[['TransactionID', 'isFraud']].rename(columns={'isFraud':'oof_1dcnn'}), how='left', on='TransactionID')\n",
    "df_oof_test = pd.merge(df_oof_test, df_oof_1dcnn_test[['TransactionID', 'isFraud']].rename(columns={'isFraud':'oof_1dcnn'}), how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>oof_lgbm</th>\n",
       "      <th>oof_xgbm</th>\n",
       "      <th>oof_mlp</th>\n",
       "      <th>oof_1dcnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.781677</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>87.781677</td>\n",
       "      <td>0.237053</td>\n",
       "      <td>2987000</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.007788</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>0.005277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>75.931198</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>75.924011</td>\n",
       "      <td>0.180677</td>\n",
       "      <td>2987001</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.010556</td>\n",
       "      <td>0.034451</td>\n",
       "      <td>0.028677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>79.129272</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>79.129272</td>\n",
       "      <td>0.156918</td>\n",
       "      <td>2987002</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.012954</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.004419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>83.263702</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>83.263580</td>\n",
       "      <td>0.191927</td>\n",
       "      <td>2987003</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.002685</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>78.967186</td>\n",
       "      <td>0.007210</td>\n",
       "      <td>78.959976</td>\n",
       "      <td>0.201674</td>\n",
       "      <td>2987004</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.012591</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss       kle  reconstructione       mse  TransactionID  oof_lgbm  \\\n",
       "0  87.781677 -0.000000        87.781677  0.237053        2987000  0.005126   \n",
       "1  75.931198  0.007184        75.924011  0.180677        2987001  0.002398   \n",
       "2  79.129272 -0.000000        79.129272  0.156918        2987002  0.001919   \n",
       "3  83.263702  0.000120        83.263580  0.191927        2987003  0.000922   \n",
       "4  78.967186  0.007210        78.959976  0.201674        2987004  0.001328   \n",
       "\n",
       "   oof_xgbm   oof_mlp  oof_1dcnn  \n",
       "0  0.007788  0.015279   0.005277  \n",
       "1  0.010556  0.034451   0.028677  \n",
       "2  0.012954  0.002952   0.004419  \n",
       "3  0.002685  0.000013   0.000802  \n",
       "4  0.001727  0.012591   0.000341  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "      <th>oof_lgbm</th>\n",
       "      <th>oof_xgbm</th>\n",
       "      <th>oof_mlp</th>\n",
       "      <th>oof_1dcnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3663549</td>\n",
       "      <td>76.213234</td>\n",
       "      <td>0.131185</td>\n",
       "      <td>76.082048</td>\n",
       "      <td>0.170198</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3663550</td>\n",
       "      <td>83.605424</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>83.479432</td>\n",
       "      <td>0.199555</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.002672</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.002861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3663551</td>\n",
       "      <td>80.684792</td>\n",
       "      <td>0.125003</td>\n",
       "      <td>80.559789</td>\n",
       "      <td>0.155993</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3663552</td>\n",
       "      <td>80.136013</td>\n",
       "      <td>0.127257</td>\n",
       "      <td>80.008757</td>\n",
       "      <td>0.156172</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3663553</td>\n",
       "      <td>78.773938</td>\n",
       "      <td>0.126601</td>\n",
       "      <td>78.647337</td>\n",
       "      <td>0.149714</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.011174</td>\n",
       "      <td>0.003880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID       loss       kle  reconstructione       mse  oof_lgbm  \\\n",
       "0        3663549  76.213234  0.131185        76.082048  0.170198  0.000186   \n",
       "1        3663550  83.605424  0.125992        83.479432  0.199555  0.001328   \n",
       "2        3663551  80.684792  0.125003        80.559789  0.155993  0.001123   \n",
       "3        3663552  80.136013  0.127257        80.008757  0.156172  0.000416   \n",
       "4        3663553  78.773938  0.126601        78.647337  0.149714  0.000441   \n",
       "\n",
       "   oof_xgbm   oof_mlp  oof_1dcnn  \n",
       "0  0.000334  0.000497   0.000324  \n",
       "1  0.002672  0.000377   0.002861  \n",
       "2  0.000482  0.001226   0.002663  \n",
       "3  0.001683  0.004226   0.001190  \n",
       "4  0.000414  0.011174   0.003880  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_oof_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_oof_train, how='left', on='TransactionID')\n",
    "df_test = pd.merge(df_test, df_oof_test, how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(folds, df_train,df_test, columns, is_output_feature_importance=1, verbose=0):\n",
    "\n",
    "#     aucs = list()\n",
    "    his = []\n",
    "    training_start_time = time()\n",
    "    df_feature_importances_i_list = []\n",
    "    df_valid_pred = pd.DataFrame()\n",
    "    df_test_pred = pd.DataFrame()\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred['TransactionID'] = df_test['TransactionID']\n",
    "    \n",
    "    X,y = df_train.sort_values('TransactionDT')[columns], df_train.sort_values('TransactionDT')['isFraud']\n",
    "    if type(df_test) != type(None):\n",
    "        X_test = df_test.sort_values('TransactionDT')[columns]\n",
    "        \n",
    "    for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "        start_time = time()\n",
    "        if verbose > 1:\n",
    "            print('Training on fold {}'.format(fold + 1))\n",
    "            \n",
    "        trn_data = lgb.Dataset(X.iloc[trn_idx], label=y.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X.iloc[test_idx], label=y.iloc[test_idx])\n",
    "        clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n",
    "        \n",
    "        y_trn_pred = clf.predict(X.iloc[trn_idx].values)\n",
    "        y_val_pred = clf.predict(X.iloc[test_idx].values)\n",
    "        \n",
    "        original_index = df_train['TransactionID'].values[test_idx]\n",
    "        df_valid_pred_i = pd.DataFrame({'TransactionID': original_index, 'predict': y_val_pred, 'fold': np.zeros(y_val_pred.shape[0]) + fold})\n",
    "        df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "        \n",
    "        y_test_pred = None\n",
    "        if type(df_test)!=type(None):\n",
    "            y_test_pred = clf.predict(X_test.values)\n",
    "            df_test_pred_i = pd.DataFrame({fold: y_test_pred})\n",
    "            df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=1)\n",
    "        \n",
    "        trn_auc = roc_auc_score(y.iloc[trn_idx].values, y_trn_pred)\n",
    "        val_auc = roc_auc_score(y.iloc[test_idx].values, y_val_pred)\n",
    "        \n",
    "        his.append({'val_auc':val_auc, 'trn_auc':trn_auc, 'y_val_pred':y_val_pred, 'y_test_pred':y_test_pred, 'test_idx':test_idx})\n",
    "        \n",
    "        if is_output_feature_importance:\n",
    "            best_iter = clf.best_iteration\n",
    "            clf = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\n",
    "            clf.fit(X.iloc[trn_idx].values, y.iloc[trn_idx].values)\n",
    "            perm = PermutationImportance(clf, random_state=42).fit(X.iloc[test_idx].values, y.iloc[test_idx].values)\n",
    "            df_feature_importances_i2 = eli5.explain_weights_dfs(perm, feature_names=columns, top=len(columns))['feature_importances']\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.sort_values(by=['feature'])\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.reset_index(drop=True)\n",
    "            df_feature_importances_i_list.append(df_feature_importances_i2)\n",
    "        \n",
    "#         aucs.append(clf.best_score['valid_1']['auc'])\n",
    "#         his.append({'val_auc':val_auc, 'trn_auc':trn_auc, 'y_val_pred':y_val_pred, 'y_test_pred':y_test_pred, 'test_idx':test_idx})\n",
    "        if verbose > 0:\n",
    "            print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    \n",
    "    his = pd.DataFrame(his)\n",
    "    \n",
    "    df_feature_importances = None\n",
    "    if is_output_feature_importance:\n",
    "        df_feature_importances = df_feature_importances_i_list[0]\n",
    "        for idx, df_feature_importances_i in enumerate(df_feature_importances_i_list[1:]):\n",
    "            df_feature_importances = pd.merge(df_feature_importances, df_feature_importances_i, on='feature', suffixes=('', idx + 1))\n",
    "            \n",
    "    df_valid_pred = df_valid_pred.sort_values(by=['TransactionID'])\n",
    "    df_valid_pred = df_valid_pred.reset_index(drop=True)\n",
    "\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred = df_test_pred.sort_values(by=['TransactionID'])\n",
    "        df_test_pred = df_test_pred.reset_index(drop=True)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('-' * 30)\n",
    "        print('Training has finished.')\n",
    "        print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "        print('Mean AUC:', his.val_auc.mean(), his.trn_auc.mean())\n",
    "        print('-' * 30)\n",
    "    return his, df_feature_importances, df_valid_pred, df_test_pred, his.val_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_test.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold 1\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's auc: 0.986899\tvalid_1's auc: 0.953091\n",
      "Fold 1 finished in 0:17:09.928580\n",
      "Training on fold 2\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's auc: 0.999997\tvalid_1's auc: 0.941207\n",
      "Early stopping, best iteration is:\n",
      "[967]\ttraining's auc: 0.999996\tvalid_1's auc: 0.941251\n"
     ]
    }
   ],
   "source": [
    "his, df_feature_importances, df_valid_pred, df_test_pred, val_metric = process(folds, df_train.iloc[100000:,:],None, columns, is_output_feature_importance=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_feature_importances(df_feature_importances, key='average_permutation_weight'):\n",
    "    df_feature_importances['average_permutation_weight'] = df_feature_importances[\n",
    "        [col for col in df_feature_importances.columns.tolist() if ('weight' in col) & ('model' not in col)]].mean(\n",
    "        axis=1)\n",
    "    df_feature_importances = df_feature_importances.sort_values(by=[key], ascending=False)\n",
    "    sorted_columns = df_feature_importances.feature.tolist()\n",
    "    return sorted_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_feature_importances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f8650fa52438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msorted_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msort_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_feature_importances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msorted_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_feature_importances' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_columns = sort_feature_importances(df_feature_importances)\n",
    "\n",
    "sorted_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred['isFraud']=df_test_pred[np.arange(8)].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred[['TransactionID','isFraud']].to_pickle(f'{folder_path}/oof_stacking_lgbm_kf8', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
