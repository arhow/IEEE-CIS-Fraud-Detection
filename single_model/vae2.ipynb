{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f'{folder_path}/df_train3.gzde', compression='gzip')#.iloc[:10000,:]\n",
    "df_test = pd.read_pickle(f'{folder_path}/df_test3.gzde', compression='gzip')#.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = df_train.replace([np.inf, -np.inf], np.nan).fillna(-999)\n",
    "\n",
    "df_test = df_test.replace([np.inf, -np.inf], np.nan).fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_emd_over_o4 = ['C7_fq_enc',\n",
    " 'ProductCD_target_mean',\n",
    " 'C4_fq_enc',\n",
    " 'id_35',\n",
    " 'addr2_fq_enc',\n",
    " 'C12_fq_enc',\n",
    " 'D7_fq_enc',\n",
    " 'V94',\n",
    " 'almost-com_addr2',\n",
    " 'addr2',\n",
    " 'V200',\n",
    " 'V201',\n",
    " 'TransactionAmt_to_mean_addr1',\n",
    " 'id_17',\n",
    " 'C8_fq_enc',\n",
    " 'ProductCD',\n",
    " 'V171',\n",
    " 'card3_TransactionAmt_std',\n",
    " 'C10_fq_enc',\n",
    " 'V170',\n",
    " 'TransactionAmt_to_std_addr1',\n",
    " 'ieee-gb-2-_id_33',\n",
    " 'email_check',\n",
    " 'card3_fq_enc',\n",
    " 'card3_count_full',\n",
    " 'id_29',\n",
    " 'id_28',\n",
    " 'V194',\n",
    " 'V242',\n",
    " 'V189',\n",
    " 'R_emaildomain_suffix',\n",
    " 'V188',\n",
    " 'V186',\n",
    " 'feature-en_R_emaildomain_suffix',\n",
    " 'extensive-_R_emaildomain_suffix',\n",
    " 'M4_target_mean',\n",
    " 'eda-and-mo_addr2',\n",
    " 'D6_fq_enc',\n",
    " 'V244',\n",
    " 'extensive-_PCA_V_17',\n",
    " 'PCA_V_17',\n",
    " 'eda-and-mo_card3',\n",
    " 'D14',\n",
    " 'V184',\n",
    " 'R_emaildomain_2',\n",
    " 'id_38',\n",
    " 'card3',\n",
    " 'id_09',\n",
    " 'id_10',\n",
    " 'ieee-gb-2-_D9',\n",
    " 'ieee-gb-2-_id_29',\n",
    " 'D8_fq_enc',\n",
    " 'V197',\n",
    " 'id_16',\n",
    " 'id_15',\n",
    " 'D12',\n",
    " 'V239',\n",
    " 'V195',\n",
    " 'V185',\n",
    " 'id_30_version',\n",
    " 'id_01_count_dist',\n",
    " 'V198',\n",
    " 'id_03',\n",
    " 'id_20',\n",
    " 'V238',\n",
    " 'ieee-gb-2-_id_16',\n",
    " 'almost-com_R_emaildomain',\n",
    " 'DeviceInfo_version_fq_enc',\n",
    " 'V243',\n",
    " 'id_31_device',\n",
    " 'eda-and-mo_id_02_to_mean_card4',\n",
    " 'id_02_to_mean_card4',\n",
    " 'eda-and-mo_id_02_to_std_card4',\n",
    " 'id_02_to_std_card4',\n",
    " 'id_04',\n",
    " 'id_02',\n",
    " 'V199',\n",
    " 'V169',\n",
    " 'id_36',\n",
    " 'ieee-gb-2-_id_31',\n",
    " 'D7',\n",
    " 'V190',\n",
    " 'V176',\n",
    " 'V191',\n",
    " 'D15_to_mean_addr2',\n",
    " 'id_02_to_mean_card1',\n",
    " 'eda-and-mo_id_02_to_mean_card1',\n",
    " 'id_02_to_std_card1',\n",
    " 'eda-and-mo_id_02_to_std_card1',\n",
    " 'id_31_count_dist',\n",
    " 'DeviceInfo_fq_enc',\n",
    " 'DeviceInfo_device_fq_enc',\n",
    " 'V196',\n",
    " 'id_11',\n",
    " 'eda-and-mo_id_11',\n",
    " 'lgb-single_id_11',\n",
    " 'D15_to_mean_addr1',\n",
    " 'eda-and-mo_D15_to_mean_addr1',\n",
    " 'V220',\n",
    " 'id_05',\n",
    " 'V251',\n",
    " 'V181',\n",
    " 'V222',\n",
    " 'V193',\n",
    " 'V187',\n",
    " 'lgb-single_V208',\n",
    " 'eda-and-mo_V208',\n",
    " 'V208',\n",
    " 'R_emaildomain_fq_enc',\n",
    " 'D15_to_std_addr1',\n",
    " 'id_31_device_fq_enc',\n",
    " 'V259',\n",
    " 'V260',\n",
    " 'V174',\n",
    " 'eda-and-mo_V214',\n",
    " 'lgb-single_V214',\n",
    " 'V214',\n",
    " 'V216',\n",
    " 'eda-and-mo_V216',\n",
    " 'lgb-single_V216',\n",
    " 'eda-and-mo_V202',\n",
    " 'lgb-single_V202',\n",
    " 'V202',\n",
    " 'eda-and-mo_V215',\n",
    " 'V215',\n",
    " 'lgb-single_V215',\n",
    " 'eda-and-mo_V211',\n",
    " 'V211',\n",
    " 'lgb-single_V206',\n",
    " 'eda-and-mo_V206',\n",
    " 'V206',\n",
    " 'eda-and-mo_V213',\n",
    " 'lgb-single_V213',\n",
    " 'V213',\n",
    " 'lgb-single_V204',\n",
    " 'V204',\n",
    " 'eda-and-mo_V204',\n",
    " 'eda-and-mo_V205',\n",
    " 'lgb-single_V205',\n",
    " 'V205',\n",
    " 'eda-and-mo_V210',\n",
    " 'lgb-single_V210',\n",
    " 'V210',\n",
    " 'eda-and-mo_V212',\n",
    " 'lgb-single_V212',\n",
    " 'V212',\n",
    " 'V221',\n",
    " 'eda-and-mo_V207',\n",
    " 'lgb-single_V207',\n",
    " 'V207',\n",
    " 'V183',\n",
    " 'V302',\n",
    " 'V250',\n",
    " 'lgb-single_V203',\n",
    " 'V203',\n",
    " 'eda-and-mo_V203',\n",
    " 'eda-and-mo_id_19',\n",
    " 'V235',\n",
    " 'V262',\n",
    " 'V192',\n",
    " 'id_36_count_dist',\n",
    " 'V247',\n",
    " 'V209',\n",
    " 'lgb-single_V209',\n",
    " 'eda-and-mo_V209',\n",
    " 'V245',\n",
    " 'V249',\n",
    " 'id_36_count_full',\n",
    " 'V256',\n",
    " 'V258',\n",
    " 'V180',\n",
    " 'V257',\n",
    " 'V172',\n",
    " 'V229',\n",
    " 'V304',\n",
    " 'V175',\n",
    " 'V255',\n",
    " 'V252',\n",
    " 'V167',\n",
    " 'V177',\n",
    " 'eda-and-mo_V271',\n",
    " 'lgb-single_V271',\n",
    " 'V271',\n",
    " 'lgb-single_V272',\n",
    " 'eda-and-mo_V272',\n",
    " 'V272',\n",
    " 'browser_id_31',\n",
    " 'V230',\n",
    " 'lgb-single_V270',\n",
    " 'eda-and-mo_V270',\n",
    " 'V270',\n",
    " 'V227',\n",
    " 'id_06',\n",
    " 'V182',\n",
    " 'V179',\n",
    " 'V168',\n",
    " 'V246',\n",
    " 'V79',\n",
    " 'V173',\n",
    " 'V248',\n",
    " 'V178',\n",
    " 'V228',\n",
    " 'V232',\n",
    " 'D13',\n",
    " 'id_13',\n",
    " 'V218',\n",
    " 'V261',\n",
    " 'ieee-gb-2-_ProductCD',\n",
    " 'V219',\n",
    " 'V237',\n",
    " 'V217',\n",
    " 'V233',\n",
    " 'id_31',\n",
    " 'V236',\n",
    " 'V231',\n",
    " 'V123',\n",
    " 'V254',\n",
    " 'id_30_device_fq_enc',\n",
    " 'V234',\n",
    " 'D15_to_std_addr2',\n",
    " 'V57',\n",
    " 'ieee-gb-2-_id_37',\n",
    " 'V253',\n",
    " 'D6',\n",
    " 'V264',\n",
    " 'lgb-single_V264',\n",
    " 'eda-and-mo_V264',\n",
    " 'eda-and-mo_V265',\n",
    " 'lgb-single_V265',\n",
    " 'V265',\n",
    " 'lgb-single_V274',\n",
    " 'eda-and-mo_V274',\n",
    " 'V274',\n",
    " 'eda-and-mo_V275',\n",
    " 'lgb-single_V275',\n",
    " 'lgb-single_V263',\n",
    " 'V263',\n",
    " 'eda-and-mo_V263',\n",
    " 'lgb-single_V273',\n",
    " 'eda-and-mo_V273',\n",
    " 'V226',\n",
    " 'lgb-single_V276',\n",
    " 'eda-and-mo_V276',\n",
    " 'V276',\n",
    " 'V225',\n",
    " 'lgb-single_V277',\n",
    " 'eda-and-mo_V277',\n",
    " 'V277',\n",
    " 'id_30_fq_enc',\n",
    " 'V278',\n",
    " 'eda-and-mo_V278',\n",
    " 'lgb-single_V278',\n",
    " 'V240',\n",
    " 'id_33_fq_enc',\n",
    " 'V241',\n",
    " 'eda-and-mo_V268',\n",
    " 'lgb-single_V268',\n",
    " 'V268',\n",
    " 'eda-and-mo_V266',\n",
    " 'lgb-single_V266',\n",
    " 'V266',\n",
    " 'eda-and-mo_V269',\n",
    " 'V269',\n",
    " 'V267',\n",
    " 'eda-and-mo_V267',\n",
    " 'lgb-single_V267',\n",
    " 'id_30_version_fq_enc',\n",
    " 'V224',\n",
    " 'V223',\n",
    " 'V303',\n",
    " 'V93',\n",
    " 'almost-com_M6',\n",
    " 'id_01',\n",
    " 'card3_TransactionAmt_mean',\n",
    " 'V92',\n",
    " 'V71',\n",
    " 'id_37',\n",
    " 'id_12',\n",
    " 'DeviceInfo_version',\n",
    " 'eda-and-mo_id_13',\n",
    " 'V21',\n",
    " 'DeviceType',\n",
    " 'id_19',\n",
    " 'V74',\n",
    " 'id_02__id_20',\n",
    " 'addr1_fq_enc',\n",
    " 'id_02__D8',\n",
    " 'PCA_V_28',\n",
    " 'lgb-single_D9',\n",
    " 'eda-and-mo_D9',\n",
    " 'D9',\n",
    " 'lgb-single_D8',\n",
    " 'eda-and-mo_D8',\n",
    " 'D8',\n",
    " 'addr1',\n",
    " 'extensive-_PCA_V_28',\n",
    " 'feature-en_R_emaildomain_bin',\n",
    " 'extensive-_R_emaildomain_bin',\n",
    " 'almost-com_addr1',\n",
    " 'V125',\n",
    " 'C5_fq_enc',\n",
    " 'V58',\n",
    " 'V73',\n",
    " 'eda-and-mo_addr1',\n",
    " 'V72',\n",
    " 'ieee-gb-2-_id_28',\n",
    " 'almost-com_ProductCD',\n",
    " 'V273',\n",
    " 'V69',\n",
    " 'R_emaildomain',\n",
    " 'V64',\n",
    " 'extensive-_PCA_V_19',\n",
    " 'PCA_V_19',\n",
    " 'V283',\n",
    " 'card6_count_full',\n",
    " 'ieee-gb-2-_card6',\n",
    " 'card6',\n",
    " 'M6',\n",
    " 'V275',\n",
    " 'V10',\n",
    " 'id_33_0',\n",
    " 'V11',\n",
    " 'V63',\n",
    " 'PCA_V_8',\n",
    " 'extensive-_PCA_V_8',\n",
    " 'PCA_V_23',\n",
    " 'extensive-_PCA_V_23',\n",
    " 'id_33_1',\n",
    " 'addr1__card1',\n",
    " 'device_version',\n",
    " 'device_name',\n",
    " 'PCA_V_34',\n",
    " 'first_value_addr1',\n",
    " 'V29',\n",
    " 'PCA_V_1',\n",
    " 'M_na',\n",
    " 'PCA_V_31',\n",
    " 'ieee-gb-2-_id_15',\n",
    " 'dist2_fq_enc',\n",
    " 'M_sum',\n",
    " 'V85',\n",
    " 'V70',\n",
    " 'M1',\n",
    " 'almost-com_M1',\n",
    " 'ieee-gb-2-_M1',\n",
    " 'V90',\n",
    " 'ieee-gb-2-_M2',\n",
    " 'dist2',\n",
    " 'V1',\n",
    " 'D11',\n",
    " 'V22',\n",
    " 'V6',\n",
    " 'V9',\n",
    " 'V111',\n",
    " 'V8',\n",
    " 'R_emaildomain_1',\n",
    " 'V3',\n",
    " 'V2',\n",
    " 'V7',\n",
    " 'eda-and-mo_id_20',\n",
    " 'V5',\n",
    " 'V4',\n",
    " 'V113',\n",
    " 'almost-com_M4',\n",
    " 'PCA_V_30',\n",
    " 'ieee-gb-2-_M3',\n",
    " 'V84',\n",
    " 'card2_TransactionAmt_mean',\n",
    " 'PCA_V_29',\n",
    " 'C2_fq_enc',\n",
    " 'V112',\n",
    " 'V114',\n",
    " 'V282',\n",
    " 'V18',\n",
    " 'PCA_V_3',\n",
    " 'V60',\n",
    " 'V50',\n",
    " 'V17',\n",
    " 'extensive-_PCA_V_29',\n",
    " 'V54',\n",
    " 'C11_fq_enc',\n",
    " 'V30',\n",
    " 'ieee-gb-2-_DeviceInfo',\n",
    " 'V59',\n",
    " 'V33',\n",
    " 'DeviceInfo_device',\n",
    " 'id_18',\n",
    " 'C1_fq_enc',\n",
    " 'DeviceInfo',\n",
    " 'V53',\n",
    " 'DeviceInfo__P_emaildomain',\n",
    " 'V15',\n",
    " 'D2',\n",
    " 'V124',\n",
    " 'M2',\n",
    " 'extensive-_PCA_V_25',\n",
    " 'extensive-_PCA_V_26',\n",
    " 'PCA_V_26',\n",
    " 'PCA_V_25',\n",
    " 'V108',\n",
    " 'PCA_V_22',\n",
    " 'D11__DeviceInfo',\n",
    " 'extensive-_PCA_V_22',\n",
    " 'V91',\n",
    " 'V31',\n",
    " 'D15_to_std_card4',\n",
    " 'eda-and-mo_D15_to_std_card4',\n",
    " 'PCA_V_4',\n",
    " 'extensive-_PCA_V_4',\n",
    " 'V116',\n",
    " 'version_id_31',\n",
    " 'D10',\n",
    " 'PCA_V_11',\n",
    " 'extensive-_PCA_V_11',\n",
    " 'V81',\n",
    " 'M3',\n",
    " 'D15_to_mean_card4',\n",
    " 'eda-and-mo_D15_to_mean_card4',\n",
    " 'id_30_device',\n",
    " 'almost-com_M7',\n",
    " 'D15',\n",
    " 'PCA_V_7',\n",
    " 'extensive-_PCA_V_7',\n",
    " 'M7',\n",
    " 'ieee-gb-2-_M9',\n",
    " 'ieee-gb-2-_M6',\n",
    " 'V13',\n",
    " 'dist1_fq_enc',\n",
    " 'V110',\n",
    " 'D1',\n",
    " 'V80',\n",
    " 'V12',\n",
    " 'extensive-_PCA_V_12',\n",
    " 'PCA_V_12',\n",
    " 'V67',\n",
    " 'V51',\n",
    " 'dist1',\n",
    " 'eda-and-mo_dist1',\n",
    " 'lgb-single_dist1',\n",
    " 'PCA_V_0',\n",
    " 'V76',\n",
    " 'PCA_V_33',\n",
    " 'card1_TransactionAmt_std',\n",
    " 'extensive-_PCA_V_10',\n",
    " 'PCA_V_10',\n",
    " 'M8',\n",
    " 'V281',\n",
    " 'V43',\n",
    " 'PCA_V_27',\n",
    " 'V75',\n",
    " 'uid2_TransactionAmt_std',\n",
    " 'ieee-gb-2-_R_emaildomain',\n",
    " 'card2_TransactionAmt_std',\n",
    " 'uid_TransactionAmt_std',\n",
    " 'extensive-_PCA_V_27',\n",
    " 'R_emaildomain_prefix',\n",
    " 'M9',\n",
    " 'V48',\n",
    " 'V34',\n",
    " 'V49',\n",
    " 'V66',\n",
    " 'V16',\n",
    " 'D2_fq_enc',\n",
    " 'V23',\n",
    " 'PCA_V_15',\n",
    " 'extensive-_PCA_V_15',\n",
    " 'V56',\n",
    " 'V32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "\n",
    "class VariationalAE(object):\n",
    "\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "\n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian\n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "\n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_dim, latent_dim, encoder_hidden_layer_sizes, decoder_hidden_layer_sizes, \n",
    "                 hidden_layer_activation_function, output_activation_function, kl_coef, drop_out, learning_rate, \n",
    "                 batch_size, epochs, random_state=0, **kwargs):\n",
    "        \n",
    "        \n",
    "        self.X_dim = X_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_hidden_layer_sizes = encoder_hidden_layer_sizes\n",
    "        self.decoder_hidden_layer_sizes = decoder_hidden_layer_sizes\n",
    "        \n",
    "        if hidden_layer_activation_function == 'relu' or hidden_layer_activation_function == 'RELU':\n",
    "            self.hidden_layer_activation_function = tf.nn.relu\n",
    "        elif hidden_layer_activation_function == 'sigmoid' or hidden_layer_activation_function == 'SIGMOID':\n",
    "            self.hidden_layer_activation_function = tf.nn.sigmoid\n",
    "        elif hidden_layer_activation_function == 'tanh' or hidden_layer_activation_function == 'TANH':\n",
    "            self.hidden_layer_activation_function = tf.nn.tanh\n",
    "        else:\n",
    "            raise Exception('unknow activation function name')\n",
    "        \n",
    "            \n",
    "        if output_activation_function == 'relu' or output_activation_function == 'RELU':\n",
    "            self.output_activation_function = tf.nn.relu\n",
    "        elif output_activation_function == 'sigmoid' or output_activation_function == 'SIGMOID':\n",
    "            self.output_activation_function = tf.nn.sigmoid\n",
    "        elif output_activation_function == 'tanh' or output_activation_function == 'TANH':\n",
    "            self.output_activation_function = tf.nn.tanh\n",
    "        elif output_activation_function == 'softplus' or output_activation_function == 'SOFTPLUS':\n",
    "            self.output_activation_function = tf.nn.softplus\n",
    "        elif output_activation_function == 'softmax' or output_activation_function == 'SOFTMAX':\n",
    "            self.output_activation_function = tf.nn.softmax\n",
    "        else:\n",
    "            raise Exception('unknow activation function name')\n",
    "            \n",
    "        self.kl_coef = kl_coef\n",
    "        self.drop_out = drop_out\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.random_state = random_state\n",
    "        self.is_training = False\n",
    "        \n",
    "        tf.set_random_seed(random_state)\n",
    "        tf.reset_default_graph()\n",
    "        self.build_graph()\n",
    "        self.compile_graph()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run([tf.local_variables_initializer(), tf.global_variables_initializer(),])\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self, X, X_val=None, **kwargs):\n",
    "        \n",
    "        his = []\n",
    "        # Training\n",
    "        n_sample = X.shape[0]\n",
    "        n_steps = int(self.epochs*n_sample/self.batch_size)\n",
    "        # input_queue = tf.train.slice_input_producer([X], shuffle=False, num_epochs=self.epochs)\n",
    "        batch_X = tf.train.batch([X], batch_size=self.batch_size, enqueue_many=True)\n",
    "\n",
    "        # self.sess.run([\n",
    "        #     tf.local_variables_initializer(),\n",
    "        #     tf.global_variables_initializer(),\n",
    "        # ])\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "            # in most cases coord.should_stop() will return True\n",
    "            # when there are no more samples to read\n",
    "            # if num_epochs=0 then it will run for ever\n",
    "            index = 1\n",
    "            while not coord.should_stop():\n",
    "                # will start reading, working data from input queue\n",
    "                # and \"fetch\" the results of the computation graph\n",
    "                # into raw_images and raw_labels\n",
    "                batch_x = self.sess.run(batch_X)\n",
    "                self.is_training = True\n",
    "                self.sess.run((self.train_op), feed_dict={self.x: batch_x, self.keep_prob: 1 - self.drop_out})\n",
    "                if (index % int(n_sample / self.batch_size) == 0):\n",
    "                    d_ = {}\n",
    "                    self.is_training = False\n",
    "                    mse, loss, kle, reconstructione = self.sess.run((self.mse, self.loss, self.kle, self.reconstructione),feed_dict={self.x: X, self.keep_prob: 1.0})\n",
    "                    d_ = {'loss': loss,'kle': kle, 'reconstructione': reconstructione, 'mse': mse}\n",
    "                    if type(X_val)!=type(None):\n",
    "                        val_mse, val_loss, val_kle, val_reconstructione = self.sess.run((self.mse, self.loss, self.kle, self.reconstructione),feed_dict={self.x: X_val, self.keep_prob: 1.0})\n",
    "                        d_ = {'val_loss': val_loss,'val_kle': val_kle, 'val_reconstructione': val_reconstructione, 'val_mse': val_mse, **d_}\n",
    "                    his.append(d_)    \n",
    "                    \n",
    "                index = index + 1\n",
    "                if index == n_steps+1:\n",
    "                    coord.request_stop()\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "\n",
    "        return his\n",
    "\n",
    "    def scores(self, X, **kwargs):\n",
    "        his = []\n",
    "        for _x in X:\n",
    "            self.is_training = False\n",
    "            mse, loss, kle, reconstructione = self.sess.run(\n",
    "                (self.mse, self.loss, self.kle, self.reconstructione),\n",
    "                feed_dict={self.x: [_x], self.keep_prob: 1.0})\n",
    "            # print('epoch loss', loss)\n",
    "            his.append(\n",
    "                {'loss': loss,\n",
    "                 'kle': kle,\n",
    "                 'reconstructione': reconstructione,\n",
    "                 'mse': mse})\n",
    "        return his\n",
    "    \n",
    "        # latent\n",
    "    def transform(self, X):\n",
    "        latent_list = []\n",
    "        for _x in X:\n",
    "            latent_list.append(self.z.eval(session=self.sess, feed_dict={self.x: [_x], self.keep_prob: 1.0}))\n",
    "        latent_array = np.array(latent_list)\n",
    "        return latent_array\n",
    "\n",
    "    # out put\n",
    "    def predict(self, X):\n",
    "        output_list = []\n",
    "        for _x in X:\n",
    "            output_list.append(self.y.eval(session=self.sess, feed_dict={self.x: [_x], self.keep_prob: 1.0}))\n",
    "        output_array = np.array(output_list)\n",
    "        return output_array\n",
    "\n",
    "    # Gaussian MLP as encoder\n",
    "    def _build_encoder(self):\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        x_ = self.x\n",
    "        input_dim = self.X_dim\n",
    "        for index, unit in enumerate(self.encoder_hidden_layer_sizes):\n",
    "            # 1st hidden layer\n",
    "            w_variable_name_ = 'encoder_w{:d}'.format(index)\n",
    "            b_variable_name_ = 'encoder_b{:d}'.format(index)\n",
    "            w = tf.get_variable(w_variable_name_, [input_dim, unit], initializer=w_init)\n",
    "            b = tf.get_variable(b_variable_name_, [unit], initializer=b_init)\n",
    "            x_ = tf.matmul(x_, w) + b\n",
    "            x_ = tf.layers.batch_normalization(x_, training=self.is_training)\n",
    "            x_ = self.hidden_layer_activation_function(x_)\n",
    "            x_ = tf.nn.dropout(x_, self.keep_prob)\n",
    "            input_dim = unit\n",
    "\n",
    "        # output layer\n",
    "        wo = tf.get_variable('encoder_wo',[unit, self.latent_dim * 2], initializer=w_init)\n",
    "        bo = tf.get_variable('encoder_bo',[self.latent_dim * 2], initializer=b_init)\n",
    "        gaussian_params = tf.matmul(x_, wo) + bo\n",
    "        gaussian_params = tf.layers.batch_normalization(gaussian_params, training=self.is_training)\n",
    "\n",
    "        # The mean parameter is unconstrained\n",
    "        self.mu = gaussian_params[:, :self.latent_dim]\n",
    "        # The standard deviation must be positive. Parametrize with a softplus and\n",
    "        # add a small epsilon for numerical stability\n",
    "        self.sigma = 1e-6 + tf.nn.softplus(gaussian_params[:, self.latent_dim:])\n",
    "\n",
    "        # sampling by re-parameterization technique\n",
    "        eps = tf.random_normal(tf.shape(self.mu), mean=0, stddev=1)\n",
    "        self.z = self.mu + self.sigma * eps\n",
    "\n",
    "\n",
    "    # Bernoulli MLP as decoder\n",
    "    def _build_decoder(self):\n",
    "\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        x_ = self.z\n",
    "        input_dim = self.latent_dim\n",
    "        for index, unit in enumerate(self.decoder_hidden_layer_sizes):\n",
    "            # 1st hidden layer\n",
    "            w_variable_name_ = 'decoder_w{:d}'.format(index)\n",
    "            b_variable_name_ = 'decoder_b{:d}'.format(index)\n",
    "            w = tf.get_variable(w_variable_name_, [input_dim, unit], initializer=w_init)\n",
    "            b = tf.get_variable(b_variable_name_, [unit], initializer=b_init)\n",
    "            x_ = tf.matmul(x_, w) + b\n",
    "            x_ = tf.layers.batch_normalization(x_, training=self.is_training)\n",
    "            x_ = self.hidden_layer_activation_function(x_)\n",
    "            x_ = tf.nn.dropout(x_, self.keep_prob)\n",
    "            input_dim = unit\n",
    "\n",
    "        # output layer-mean\n",
    "        wo = tf.get_variable('decoder_wo',[unit, self.X_dim], initializer=w_init)\n",
    "        bo = tf.get_variable('decoder_bo',[self.X_dim], initializer=b_init)\n",
    "        params = tf.matmul(x_, wo) + bo\n",
    "        params = tf.layers.batch_normalization(params, training=self.is_training)\n",
    "        self.y = self.output_activation_function(params, name='output')\n",
    "\n",
    "        return\n",
    "\n",
    "    def _loss(self):\n",
    "\n",
    "        local_epsilon = 1e-6\n",
    "        # marginal_likelihood = self.x * tf.log(tf.clip_by_value(self.y, local_epsilon, 1.0)) + \\\n",
    "        #                             (1 - self.x) * tf.log(tf.clip_by_value(1 - self.y, local_epsilon, 1.0))\n",
    "        y_ = tf.clip_by_value(self.y, local_epsilon, 1 - local_epsilon)\n",
    "        x_ = tf.clip_by_value(self.x, local_epsilon, 1 - local_epsilon)\n",
    "        marginal_likelihood = x_ * tf.log(y_) + (1 - x_) * tf.log(1 - y_)\n",
    "        marginal_likelihood = -1 * tf.reduce_sum(marginal_likelihood, 1)\n",
    "\n",
    "        mu_ = tf.clip_by_value(self.mu, local_epsilon, 1 - local_epsilon)\n",
    "        sigma_ = tf.clip_by_value(self.sigma, local_epsilon, 1 - local_epsilon)\n",
    "        kl_divergence = 1 + tf.log(tf.square(sigma_)) - tf.square(mu_) - tf.square(sigma_)\n",
    "        kl_divergence = -self.kl_coef * tf.reduce_sum(kl_divergence, 1)\n",
    "\n",
    "        self.loss = tf.reduce_mean(marginal_likelihood + kl_divergence, name='loss')\n",
    "        self.mse = tf.sqrt(tf.losses.mean_squared_error(self.y, self.x), name='mse')\n",
    "        self.kle = tf.reduce_mean(kl_divergence, name='kle')\n",
    "        self.reconstructione = tf.reduce_mean(marginal_likelihood, name='reconstructione')\n",
    "        return\n",
    "\n",
    "\n",
    "    def compile_graph(self):\n",
    "        \n",
    "        # loss\n",
    "        self._loss()\n",
    "        # train\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        return\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.X_dim], name='input')\n",
    "        # encoding\n",
    "        self._build_encoder()\n",
    "        # decoding\n",
    "        self._build_decoder()\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(folds, df_train,df_test, columns, verbose=0):\n",
    "\n",
    "#     aucs = list()\n",
    "    his = []\n",
    "    training_start_time = time()\n",
    "    df_valid_pred = pd.DataFrame()\n",
    "    df_test_pred = pd.DataFrame()\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred['TransactionID'] = df_test['TransactionID'].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[columns].values)\n",
    "        \n",
    "    for fold, (trn_idx, test_idx) in enumerate(folds.split(df_train)):\n",
    "        start_time = time()\n",
    "        if verbose > 1:\n",
    "            print('Training on fold {}'.format(fold + 1))\n",
    "        \n",
    "        vae = VariationalAE(**params)\n",
    "        train_his = vae.fit(scaler.transform(df_train.iloc[trn_idx][df_train['isFraud']==0][columns].values))\n",
    "        scores = vae.scores(scaler.transform(df_train.iloc[test_idx][columns].values))\n",
    "        \n",
    "        df_valid_pred_i = pd.DataFrame(scores)\n",
    "        df_valid_pred_i['TransactionID'] = df_train['TransactionID'].values[test_idx]\n",
    "        df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "        \n",
    "        y_test_pred = None\n",
    "        if type(df_test)!=type(None):\n",
    "            scores = vae.scores(scaler.transform(df_test[columns].values))\n",
    "            df_test_pred_i = pd.DataFrame(scores)\n",
    "            df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=1)\n",
    "        \n",
    "        \n",
    "#         aucs.append(clf.best_score['valid_1']['auc'])\n",
    "        his.append({'train_his':train_his, 'df_valid_pred_i':df_valid_pred_i, 'test_idx':test_idx})\n",
    "        if verbose > 0:\n",
    "            print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    his = pd.DataFrame(his)\n",
    "            \n",
    "    df_valid_pred = df_valid_pred.sort_values(by=['TransactionID'])\n",
    "    df_valid_pred = df_valid_pred.reset_index(drop=True)\n",
    "\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred = df_test_pred.sort_values(by=['TransactionID'])\n",
    "        df_test_pred = df_test_pred.reset_index(drop=True)\n",
    "        \n",
    "        df_test_pred_mean = pd.DataFrame()\n",
    "        df_test_pred_mean['TransactionID'] = df_test_pred['TransactionID'].values\n",
    "        df_test_pred_mean['loss'] = df_test_pred['loss'].mean(axis=1).values\n",
    "        df_test_pred_mean['kle'] = df_test_pred['kle'].mean(axis=1).values\n",
    "        df_test_pred_mean['reconstructione'] = df_test_pred['reconstructione'].mean(axis=1).values\n",
    "        df_test_pred_mean['mse'] = df_test_pred['mse'].mean(axis=1).values\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('-' * 30)\n",
    "        print('Training has finished.')\n",
    "        print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "        print('-' * 30)\n",
    "    return his, df_valid_pred, df_test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 926), (506691, 925), 468)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape,len(columns_emd_over_o4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=8, shuffle=False, random_state=42)\n",
    "params = {\n",
    "    'X_dim': len(columns_emd_over_o4),\n",
    "    'latent_dim': 2,\n",
    "    'encoder_hidden_layer_sizes':[1024, 256],\n",
    "    'decoder_hidden_layer_sizes':[512],\n",
    "    'hidden_layer_activation_function':'relu',\n",
    "    'output_activation_function':'sigmoid',\n",
    "    'kl_coef': .5,\n",
    "    'drop_out': 0.1,                \n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-7-c7e40a9cb900>:163: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c7e40a9cb900>:165: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-7-c7e40a9cb900>:77: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-7-c7e40a9cb900>:84: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[498047,468] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_3 (defined at <ipython-input-7-c7e40a9cb900>:222) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node loss (defined at <ipython-input-7-c7e40a9cb900>:230) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_3', defined at:\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-65f275853e19>\", line 1, in <module>\n    his, df_valid_pred, df_test_pred = process(folds, df_train,df_test, columns_emd_over_o4, verbose=1)\n  File \"<ipython-input-8-dde56790e42d>\", line 19, in process\n    vae = VariationalAE(**params)\n  File \"<ipython-input-7-c7e40a9cb900>\", line 63, in __init__\n    self.compile_graph()\n  File \"<ipython-input-7-c7e40a9cb900>\", line 240, in compile_graph\n    self._loss()\n  File \"<ipython-input-7-c7e40a9cb900>\", line 222, in _loss\n    marginal_likelihood = x_ * tf.log(y_) + (1 - x_) * tf.log(1 - y_)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 840, in r_binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 9536, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[498047,468] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_3 (defined at <ipython-input-7-c7e40a9cb900>:222) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node loss (defined at <ipython-input-7-c7e40a9cb900>:230) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[498047,468] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sub_3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[{{node loss}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-65f275853e19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_valid_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns_emd_over_o4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-dde56790e42d>\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(folds, df_train, df_test, columns, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariationalAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrain_his\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isFraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-c7e40a9cb900>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, X_val, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0md_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstructione\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconstructione\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0md_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'kle'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reconstructione'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreconstructione\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mse'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[498047,468] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_3 (defined at <ipython-input-7-c7e40a9cb900>:222) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node loss (defined at <ipython-input-7-c7e40a9cb900>:230) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'sub_3', defined at:\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-65f275853e19>\", line 1, in <module>\n    his, df_valid_pred, df_test_pred = process(folds, df_train,df_test, columns_emd_over_o4, verbose=1)\n  File \"<ipython-input-8-dde56790e42d>\", line 19, in process\n    vae = VariationalAE(**params)\n  File \"<ipython-input-7-c7e40a9cb900>\", line 63, in __init__\n    self.compile_graph()\n  File \"<ipython-input-7-c7e40a9cb900>\", line 240, in compile_graph\n    self._loss()\n  File \"<ipython-input-7-c7e40a9cb900>\", line 222, in _loss\n    marginal_likelihood = x_ * tf.log(y_) + (1 - x_) * tf.log(1 - y_)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 840, in r_binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 9536, in sub\n    \"Sub\", x=x, y=y, name=name)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ubuntu/.conda/envs/py-wang/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[498047,468] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node sub_3 (defined at <ipython-input-7-c7e40a9cb900>:222) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[node loss (defined at <ipython-input-7-c7e40a9cb900>:230) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "his, df_valid_pred, df_test_pred = process(folds, df_train,df_test, columns_emd_over_o4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "      <th>TransactionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>114.867157</td>\n",
       "      <td>0.502394</td>\n",
       "      <td>114.364761</td>\n",
       "      <td>0.152810</td>\n",
       "      <td>2987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99.665977</td>\n",
       "      <td>0.519566</td>\n",
       "      <td>99.146408</td>\n",
       "      <td>0.121638</td>\n",
       "      <td>2987001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>106.663673</td>\n",
       "      <td>0.502882</td>\n",
       "      <td>106.160789</td>\n",
       "      <td>0.100766</td>\n",
       "      <td>2987002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>127.823006</td>\n",
       "      <td>0.658024</td>\n",
       "      <td>127.164978</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>2987003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166.206467</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>166.175385</td>\n",
       "      <td>0.143271</td>\n",
       "      <td>2987004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>161.074203</td>\n",
       "      <td>0.534761</td>\n",
       "      <td>160.539444</td>\n",
       "      <td>0.134931</td>\n",
       "      <td>2996995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>120.351067</td>\n",
       "      <td>1.159901</td>\n",
       "      <td>119.191162</td>\n",
       "      <td>0.186028</td>\n",
       "      <td>2996996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>108.676117</td>\n",
       "      <td>1.109847</td>\n",
       "      <td>107.566269</td>\n",
       "      <td>0.115891</td>\n",
       "      <td>2996997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>111.611336</td>\n",
       "      <td>0.504733</td>\n",
       "      <td>111.106606</td>\n",
       "      <td>0.135386</td>\n",
       "      <td>2996998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>81.563492</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>81.548172</td>\n",
       "      <td>0.118210</td>\n",
       "      <td>2996999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss       kle  reconstructione       mse  TransactionID\n",
       "0     114.867157  0.502394       114.364761  0.152810        2987000\n",
       "1      99.665977  0.519566        99.146408  0.121638        2987001\n",
       "2     106.663673  0.502882       106.160789  0.100766        2987002\n",
       "3     127.823006  0.658024       127.164978  0.146039        2987003\n",
       "4     166.206467  0.031082       166.175385  0.143271        2987004\n",
       "...          ...       ...              ...       ...            ...\n",
       "9995  161.074203  0.534761       160.539444  0.134931        2996995\n",
       "9996  120.351067  1.159901       119.191162  0.186028        2996996\n",
       "9997  108.676117  1.109847       107.566269  0.115891        2996997\n",
       "9998  111.611336  0.504733       111.106606  0.135386        2996998\n",
       "9999   81.563492  0.015317        81.548172  0.118210        2996999\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2997000</td>\n",
       "      <td>118.942210</td>\n",
       "      <td>0.770884</td>\n",
       "      <td>118.171326</td>\n",
       "      <td>0.146101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2997001</td>\n",
       "      <td>111.266341</td>\n",
       "      <td>0.517203</td>\n",
       "      <td>110.749136</td>\n",
       "      <td>0.135822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2997002</td>\n",
       "      <td>110.686563</td>\n",
       "      <td>0.491461</td>\n",
       "      <td>110.195102</td>\n",
       "      <td>0.120008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2997003</td>\n",
       "      <td>98.938614</td>\n",
       "      <td>0.362082</td>\n",
       "      <td>98.576534</td>\n",
       "      <td>0.102681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2997004</td>\n",
       "      <td>111.863249</td>\n",
       "      <td>0.955579</td>\n",
       "      <td>110.907671</td>\n",
       "      <td>0.151147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>3006995</td>\n",
       "      <td>198.098608</td>\n",
       "      <td>2.875278</td>\n",
       "      <td>195.223331</td>\n",
       "      <td>0.200928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>3006996</td>\n",
       "      <td>122.023468</td>\n",
       "      <td>0.497102</td>\n",
       "      <td>121.526366</td>\n",
       "      <td>0.203341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>3006997</td>\n",
       "      <td>120.004228</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>119.541174</td>\n",
       "      <td>0.198779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>3006998</td>\n",
       "      <td>128.002359</td>\n",
       "      <td>0.535765</td>\n",
       "      <td>127.466599</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>3006999</td>\n",
       "      <td>162.257040</td>\n",
       "      <td>0.834633</td>\n",
       "      <td>161.422412</td>\n",
       "      <td>0.187575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TransactionID        loss       kle  reconstructione       mse\n",
       "0           2997000  118.942210  0.770884       118.171326  0.146101\n",
       "1           2997001  111.266341  0.517203       110.749136  0.135822\n",
       "2           2997002  110.686563  0.491461       110.195102  0.120008\n",
       "3           2997003   98.938614  0.362082        98.576534  0.102681\n",
       "4           2997004  111.863249  0.955579       110.907671  0.151147\n",
       "...             ...         ...       ...              ...       ...\n",
       "9995        3006995  198.098608  2.875278       195.223331  0.200928\n",
       "9996        3006996  122.023468  0.497102       121.526366  0.203341\n",
       "9997        3006997  120.004228  0.463054       119.541174  0.198779\n",
       "9998        3006998  128.002359  0.535765       127.466599  0.212015\n",
       "9999        3006999  162.257040  0.834633       161.422412  0.187575\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-wang",
   "language": "python",
   "name": "py-wang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
