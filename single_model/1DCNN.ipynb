{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.initializers import glorot_uniform, lecun_uniform\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPool1D, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trans = pd.read_csv(f'{folder_path}train_transaction.csv').iloc[:6000,:]\n",
    "df_id = pd.read_csv(f'{folder_path}train_identity.csv').iloc[:6000,:]\n",
    "df_train = pd.merge(df_trans, df_id, how='left', on='TransactionID')\n",
    "del df_trans\n",
    "del df_id\n",
    "\n",
    "df_trans = pd.read_csv(f'{folder_path}test_transaction.csv').iloc[:1000,:]\n",
    "df_id = pd.read_csv(f'{folder_path}test_identity.csv').iloc[:1000,:]\n",
    "df_test = pd.merge(df_trans, df_id, how='left', on='TransactionID')\n",
    "del df_trans\n",
    "del df_id\n",
    "\n",
    "na_exist_columns = []\n",
    "for col in df_test.columns:\n",
    "    if df_train[col].isnull().sum()>0:\n",
    "        na_exist_columns.append(col)\n",
    "    else:\n",
    "        if df_test[col].isnull().sum()>0:\n",
    "            na_exist_columns.append(col)\n",
    "            \n",
    "# train_isnull = df_train[na_exist_columns].isnull().astype(int)\n",
    "# train_isnull.columns = [f'{col}_isna' for col in train_isnull.columns]\n",
    "# test_isnull = df_test[na_exist_columns].isnull().astype(int)\n",
    "# test_isnull.columns = [f'{col}_isna' for col in test_isnull.columns]\n",
    "\n",
    "for col in df_test.columns:\n",
    "    try:\n",
    "        if not is_numeric_dtype(df_test[col]):\n",
    "            le = LabelEncoder()\n",
    "            le.fit(df_train[col].fillna('').tolist() + df_test[col].fillna('').tolist())\n",
    "            df_train[col] = le.transform(df_train[col].fillna(''))\n",
    "            df_test[col] = le.transform(df_test[col].fillna(''))\n",
    "        else:\n",
    "            min_ = np.min([df_train[col].dropna().min(), df_test[col].dropna().min()])\n",
    "            max_ = np.max([df_train[col].dropna().max(), df_test[col].dropna().max()])\n",
    "            replace_value = min_- (max_ - min_)*.1\n",
    "            df_train[col] = df_train[col].fillna(replace_value)\n",
    "            df_test[col] = df_test[col].fillna(replace_value)\n",
    "    except:\n",
    "        raise Exception(f'{col}-{df_train[col].dtype}')\n",
    "        \n",
    "for col in df_train.columns:\n",
    "     if not is_numeric_dtype(df_train[col]):\n",
    "        print(col, df_train[col].dtype)\n",
    "        \n",
    "for col in df_test.columns:\n",
    "     if not is_numeric_dtype(df_test[col]):\n",
    "        print(col, df_test[col].dtype)\n",
    "        \n",
    "        \n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train[df_test.columns.tolist()].values)\n",
    "\n",
    "X_train = pd.DataFrame(scaler.transform(df_train[df_test.columns.tolist()].values)*255).astype(int).values\n",
    "# X_train = pd.concat([X_train, train_isnull], axis=1).values\n",
    "\n",
    "y_train = df_train['isFraud'].values\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(df_test[df_test.columns.tolist()].values)*255).astype(int).values\n",
    "# X_test = pd.concat([X_test, test_isnull], axis=1).values\n",
    "\n",
    "del df_train\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f'{folder_path}/df_train2.gzde', compression='gzip').iloc[:6000,:]\n",
    "df_test = pd.read_pickle(f'{folder_path}/df_test2.gzde', compression='gzip').iloc[:1000,:]\n",
    "\n",
    "columns = df_train.columns.tolist()\n",
    "columns.remove('TransactionID')\n",
    "columns.remove('TransactionDT')\n",
    "columns.remove('isFraud')\n",
    "\n",
    "X_train = df_train[columns].values\n",
    "y_train = df_train['isFraud'].values\n",
    "X_test = df_test[columns].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train, 2)\n",
    "X_test = np.expand_dims(X_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_folds = 5\n",
    "# folds = TimeSeriesSplit(n_splits=number_of_folds)\n",
    "folds = KFold(n_splits=number_of_folds, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EarlyStop(patience):\n",
    "    return EarlyStopping(monitor = \"val_loss\",\n",
    "                          min_delta = 0,\n",
    "                          mode = \"min\",\n",
    "                          verbose = 1, \n",
    "                          patience = patience)\n",
    "\n",
    "def ModelCheckpointFull(model_name):\n",
    "    return ModelCheckpoint(model_name, \n",
    "                            monitor = 'val_loss', \n",
    "                            verbose = 1, \n",
    "                            save_best_only = True, \n",
    "                            save_weights_only = False, \n",
    "                            mode = 'min', \n",
    "                            period = 1)\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "filters = 96\n",
    "\n",
    "# Define CNN 1D model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters, 2, activation = 'relu', input_shape=(input_shape, 1), kernel_initializer = glorot_uniform(seed = seed)))\n",
    "    model.add(BatchNormalization())       \n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    for _ in range(2):\n",
    "        model.add(Conv1D(filters, 1, activation = 'relu', kernel_initializer = glorot_uniform(seed = seed)))\n",
    "        model.add(BatchNormalization())       \n",
    "        model.add(Dropout(0.25))    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation = 'relu', kernel_initializer = glorot_uniform(seed = seed)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128, activation = 'relu', kernel_initializer = glorot_uniform(seed = seed)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(1, activation = 'sigmoid', kernel_initializer = glorot_uniform(seed = seed)))\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = Adam(lr = 0.0005), metrics = [auc])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Fold: 0\n",
      "Epoch 00028: early stopping\n",
      "Fold  0 AUC : 0.852643\n",
      "Running Fold: 1\n",
      "Epoch 00032: early stopping\n",
      "Fold  1 AUC : 0.744725\n",
      "Running Fold: 2\n",
      "Epoch 00026: early stopping\n",
      "Fold  2 AUC : 0.750634\n",
      "Running Fold: 3\n",
      "Epoch 00025: early stopping\n",
      "Fold  3 AUC : 0.776603\n",
      "Running Fold: 4\n",
      "Epoch 00027: early stopping\n",
      "Fold  4 AUC : 0.879061\n",
      "Full AUC score 0.735906\n"
     ]
    }
   ],
   "source": [
    "# Random Seed\n",
    "seed = 12345\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Constants\n",
    "epochs = 200\n",
    "batch_size = 1024\n",
    "\n",
    "# Input Shape\n",
    "input_shape = X_train.shape[1]\n",
    "\n",
    "# Arrays to store predictions\n",
    "oof_preds = np.zeros(X_train.shape[0])\n",
    "sub_preds = np.zeros(X_test.shape[0])\n",
    "\n",
    "# X_test = np.expand_dims(X_test, 2)\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    train_x, train_y = X_train[train_idx], y_train[train_idx]\n",
    "    valid_x, valid_y = X_train[valid_idx], y_train[valid_idx]\n",
    "    \n",
    "    # Reshape\n",
    "#     train_x = np.expand_dims(train_x, 2)\n",
    "#     valid_x = np.expand_dims(valid_x, 2)\n",
    "\n",
    "    print('Running Fold: ' + str(n_fold))\n",
    "\n",
    "    # CNN 1D model\n",
    "    model = create_model()\n",
    "    model.fit(train_x, train_y, \n",
    "                validation_data=(valid_x, valid_y), \n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size, \n",
    "                verbose=0,\n",
    "                callbacks=[EarlyStop(20)])#, ModelCheckpointFull('model.h5')\n",
    "\n",
    "    # Delete Model\n",
    "#     del model\n",
    "#     gc.collect()\n",
    "\n",
    "    # Reload Best Saved Model\n",
    "#     model = load_model('model.h5')\n",
    "\n",
    "    # OOF Predictions\n",
    "    oof_preds[valid_idx] = model.predict(valid_x).reshape(-1,)\n",
    "    \n",
    "    # Submission Predictions\n",
    "    predictions = model.predict(X_test).reshape(-1,)\n",
    "    sub_preds += predictions / number_of_folds\n",
    "\n",
    "    # Fold AUC Score\n",
    "    print('Fold %2d AUC : %.6f' % (n_fold, roc_auc_score(valid_y, oof_preds[valid_idx])))        \n",
    "\n",
    "    # Cleanup \n",
    "    del model, train_x, train_y, valid_y, valid_x\n",
    "    K.clear_session()\n",
    "    gc.collect\n",
    "\n",
    "print('Full AUC score %.6f' % roc_auc_score(y_train, oof_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
