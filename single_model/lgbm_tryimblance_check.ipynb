{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from time import time\n",
    "import datetime\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "warnings.simplefilter('ignore')\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as sk_mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "class processutil:\n",
    "    def _str2class(s):\n",
    "        if s in globals() and isinstance(globals()[s], type):\n",
    "                return globals()[s]\n",
    "        if isinstance(eval(s), type):\n",
    "            return eval(s)\n",
    "        if callable(eval(s)):\n",
    "            return eval(s)\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f'{folder_path}/df_train2.gzde', compression='gzip')#.iloc[:100000,:]\n",
    "# df_test = pd.read_pickle(f'{folder_path}/df_test2.gzde', compression='gzip').iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns.tolist()\n",
    "columns.remove('TransactionID')\n",
    "columns.remove('TransactionDT')\n",
    "columns.remove('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'num_leaves': 491,\n",
    "          'min_child_weight': 0.03454472573214212,\n",
    "          'feature_fraction': 0.3797454081646243,\n",
    "          'bagging_fraction': 0.4181193142567742,\n",
    "          'min_data_in_leaf': 106,\n",
    "          'objective': 'binary',\n",
    "          'max_depth': -1,\n",
    "          'learning_rate': 0.006883242363721497,\n",
    "          \"boosting_type\": \"gbdt\",\n",
    "          \"bagging_seed\": 11,\n",
    "          \"metric\": 'auc',\n",
    "          \"verbosity\": -1,\n",
    "          'reg_alpha': 0.3899927210061127,\n",
    "          'reg_lambda': 0.6485237330340494,\n",
    "          'random_state': 47\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(ratio='minority')\n",
    "# X_sm, y_sm = smote.fit_sample(X, y)\n",
    "\n",
    "# plot_2d_space(X_sm, y_sm,X,y, 'SMOTE over-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ran=RandomUnderSampler(return_indices=True) ##intialize to return indices of dropped rows\n",
    "# X_rs,y_rs,dropped = ran.fit_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(folds, df_train,df_test, columns, is_output_feature_importance=1, verbose=0):\n",
    "\n",
    "#     aucs = list()\n",
    "    his = []\n",
    "    training_start_time = time()\n",
    "    df_feature_importances_i_list = []\n",
    "    df_valid_pred = pd.DataFrame()\n",
    "    df_test_pred = pd.DataFrame()\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred['TransactionID'] = df_test['TransactionID']\n",
    "    \n",
    "    X,y = df_train.sort_values('TransactionDT')[columns], df_train.sort_values('TransactionDT')['isFraud']\n",
    "    if type(df_test) != type(None):\n",
    "        X_test = df_test.sort_values('TransactionDT')[columns]\n",
    "        \n",
    "    for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "        start_time = time()\n",
    "        if verbose > 1:\n",
    "            print('Training on fold {}'.format(fold + 1))\n",
    "\n",
    "\n",
    "#         smote = SMOTE(ratio='minority')\n",
    "#         X_train_fold_n, y_train_fold_n = smote.fit_sample(X.iloc[trn_idx], y.iloc[trn_idx])\n",
    "#         ran=RandomUnderSampler(return_indices=True) \n",
    "#         X_train_fold_n, y_train_fold_n,dropped = ran.fit_sample(X.iloc[trn_idx], y.iloc[trn_idx])\n",
    "        \n",
    "        ss = StandardScaler()\n",
    "        X_train_fold_n, y_train_fold_n = ss.fit_transform(X.iloc[trn_idx] ), y.iloc[trn_idx]\n",
    "        X_test_fold_n, y_test_fold_n = ss.transform(X.iloc[test_idx]), y.iloc[test_idx]\n",
    "        \n",
    "        trn_data = lgb.Dataset(X_train_fold_n, label=y_train_fold_n)\n",
    "        val_data = lgb.Dataset(X_test_fold_n, label=y_test_fold_n)\n",
    "        clf = lgb.train(params, trn_data, 10000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds=500)\n",
    "        \n",
    "        y_trn_pred = clf.predict(X.iloc[trn_idx].values)\n",
    "        y_val_pred = clf.predict(X.iloc[test_idx].values)\n",
    "        \n",
    "        original_index = df_train['TransactionID'].values[test_idx]\n",
    "        df_valid_pred_i = pd.DataFrame({'TransactionID': original_index, 'predict': y_val_pred, 'fold': np.zeros(y_val_pred.shape[0]) + fold})\n",
    "        df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "        \n",
    "        y_test_pred = None\n",
    "        if type(df_test)!=type(None):\n",
    "            y_test_pred = clf.predict(X_test.values)\n",
    "            df_test_pred_i = pd.DataFrame({fold: y_test_pred})\n",
    "            df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=1)\n",
    "        \n",
    "        trn_auc = roc_auc_score(y.iloc[trn_idx].values, y_trn_pred)\n",
    "        val_auc = roc_auc_score(y.iloc[test_idx].values, y_val_pred)\n",
    "        \n",
    "        his.append({'val_auc':val_auc, 'trn_auc':trn_auc, 'y_val_pred':y_val_pred, 'y_test_pred':y_test_pred, 'test_idx':test_idx})\n",
    "        \n",
    "        if is_output_feature_importance:\n",
    "            best_iter = clf.best_iteration\n",
    "            clf = lgb.LGBMClassifier(**params, num_boost_round=best_iter)\n",
    "            clf.fit(X.iloc[trn_idx].values, y.iloc[trn_idx].values)\n",
    "            perm = PermutationImportance(clf, random_state=42).fit(X.iloc[test_idx].values, y.iloc[test_idx].values)\n",
    "            df_feature_importances_i2 = eli5.explain_weights_dfs(perm, feature_names=columns, top=len(columns))['feature_importances']\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.sort_values(by=['feature'])\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.reset_index(drop=True)\n",
    "            df_feature_importances_i_list.append(df_feature_importances_i2)\n",
    "        \n",
    "#         aucs.append(clf.best_score['valid_1']['auc'])\n",
    "#         his.append({'val_auc':val_auc, 'trn_auc':trn_auc, 'y_val_pred':y_val_pred, 'y_test_pred':y_test_pred, 'test_idx':test_idx})\n",
    "        if verbose > 0:\n",
    "            print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    \n",
    "    his = pd.DataFrame(his)\n",
    "    \n",
    "    df_feature_importances = None\n",
    "    if is_output_feature_importance:\n",
    "        df_feature_importances = df_feature_importances_i_list[0]\n",
    "        for idx, df_feature_importances_i in enumerate(df_feature_importances_i_list[1:]):\n",
    "            df_feature_importances = pd.merge(df_feature_importances, df_feature_importances_i, on='feature', suffixes=('', idx + 1))\n",
    "            \n",
    "    df_valid_pred = df_valid_pred.sort_values(by=['TransactionID'])\n",
    "    df_valid_pred = df_valid_pred.reset_index(drop=True)\n",
    "\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred = df_test_pred.sort_values(by=['TransactionID'])\n",
    "        df_test_pred = df_test_pred.reset_index(drop=True)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('-' * 30)\n",
    "        print('Training has finished.')\n",
    "        print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "        print('Mean AUC:', his.val_auc.mean(), his.trn_auc.mean())\n",
    "        print('-' * 30)\n",
    "    return his, df_feature_importances, df_valid_pred, df_test_pred, his.val_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "folds = KFold(n_splits=8, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's auc: 0.999006\tvalid_1's auc: 0.92588\n",
      "[2000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.927713\n",
      "[3000]\ttraining's auc: 1\tvalid_1's auc: 0.928073\n",
      "Early stopping, best iteration is:\n",
      "[2521]\ttraining's auc: 1\tvalid_1's auc: 0.927938\n",
      "Fold 1 finished in 4:50:52.627341\n",
      "Training until validation scores don't improve for 500 rounds.\n",
      "[1000]\ttraining's auc: 0.998934\tvalid_1's auc: 0.940446\n",
      "[2000]\ttraining's auc: 0.999999\tvalid_1's auc: 0.943979\n",
      "Early stopping, best iteration is:\n",
      "[2093]\ttraining's auc: 1\tvalid_1's auc: 0.944104\n"
     ]
    }
   ],
   "source": [
    "his, df_feature_importances, df_valid_pred, df_test_pred, val_metric = process(folds, df_train,None, columns, is_output_feature_importance=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean AUC: 0.9271172613055931 0.9999956794809108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
