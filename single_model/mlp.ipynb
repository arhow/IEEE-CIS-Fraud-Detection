{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f'{folder_path}/df_train2.gzde', compression='gzip')#.iloc[:10000,:]\n",
    "df_test = pd.read_pickle(f'{folder_path}/df_test2.gzde', compression='gzip')#.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_test.columns.tolist()\n",
    "columns.remove('TransactionID')\n",
    "columns.remove('TransactionDT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn_model(input_shape, num_classes):\n",
    "    dropout = .2\n",
    "    inp = Input(shape=(input_shape,))\n",
    "    x = Dense(2048, activation=\"relu\")(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "    for i in range(1):\n",
    "        x = Dense(1024, activation=\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "#         x = Dropout(dropout)(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "#     x = Dropout(dropout)(x)\n",
    "    \n",
    "#     out = Dense(1, activation=\"linear\")(x)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=[out])\n",
    "    return model\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GPU preferences\n",
    "config = tf.ConfigProto( device_count = {'GPU': 1 , 'CPU': 2} ) \n",
    "config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "sess = tf.Session(config=config) \n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\n",
    "    'batch_size':64,\n",
    "    'epochs':200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(folds, df_train,df_test, columns, is_output_feature_importance=1, verbose=0):\n",
    "\n",
    "#     aucs = list()\n",
    "    his = []\n",
    "    training_start_time = time()\n",
    "    df_feature_importances_i_list = []\n",
    "    df_valid_pred = pd.DataFrame()\n",
    "    df_test_pred = pd.DataFrame()\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred['TransactionID'] = df_test['TransactionID']\n",
    "    \n",
    "    X,y = df_train.sort_values('TransactionDT')[columns], df_train.sort_values('TransactionDT')['isFraud']\n",
    "    if type(df_test) != type(None):\n",
    "        X_test = df_test.sort_values('TransactionDT')[columns]\n",
    "        \n",
    "    for fold, (trn_idx, test_idx) in enumerate(folds.split(X, y)):\n",
    "        start_time = time()\n",
    "        if verbose > 1:\n",
    "            print('Training on fold {}'.format(fold + 1))\n",
    "        \n",
    "        clf = nn_model=create_nn_model(X.shape[1], 2)\n",
    "        clf.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=[auc])\n",
    "        \n",
    "        train_history = clf.fit(X.iloc[trn_idx].values, y.iloc[trn_idx].values, validation_data=(X.iloc[test_idx].values, y.iloc[test_idx].values), **fit_params)\n",
    "        \n",
    "        y_trn_pred = clf.predict(X.iloc[trn_idx].values) [:,0]\n",
    "        y_val_pred = clf.predict(X.iloc[test_idx].values)[:,0]\n",
    "        \n",
    "        original_index = df_train['TransactionID'].values[test_idx]\n",
    "        df_valid_pred_i = pd.DataFrame({'TransactionID': original_index, 'predict': y_val_pred, 'fold': np.zeros(y_val_pred.shape[0]) + fold})\n",
    "        df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "        \n",
    "        y_test_pred = None\n",
    "        if type(df_test)!=type(None):\n",
    "            y_test_pred = clf.predict(X_test.values)[:,0]\n",
    "            df_test_pred_i = pd.DataFrame({fold: y_test_pred})\n",
    "            df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=1)\n",
    "        \n",
    "        trn_auc = roc_auc_score(y.iloc[trn_idx].values, y_trn_pred)\n",
    "        val_auc = roc_auc_score(y.iloc[test_idx].values, y_val_pred)\n",
    "        \n",
    "        if is_output_feature_importance:\n",
    "            perm = PermutationImportance(clf, random_state=42).fit(X.iloc[test_idx].values, y.iloc[test_idx].values)\n",
    "            df_feature_importances_i2 = eli5.explain_weights_dfs(perm, feature_names=columns, top=len(columns))['feature_importances']\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.sort_values(by=['feature'])\n",
    "            df_feature_importances_i2 = df_feature_importances_i2.reset_index(drop=True)\n",
    "            df_feature_importances_i_list.append(df_feature_importances_i2)\n",
    "        \n",
    "#         aucs.append(clf.best_score['valid_1']['auc'])\n",
    "        his.append({'val_auc':val_auc, 'trn_auc':trn_auc, 'y_val_pred':y_val_pred, 'y_test_pred':y_test_pred, 'test_idx':test_idx})\n",
    "        if verbose > 0:\n",
    "            print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    his = pd.DataFrame(his)\n",
    "    \n",
    "    df_feature_importances = None\n",
    "    if is_output_feature_importance:\n",
    "        df_feature_importances = df_feature_importances_i_list[0]\n",
    "        for idx, df_feature_importances_i in enumerate(df_feature_importances_i_list[1:]):\n",
    "            df_feature_importances = pd.merge(df_feature_importances, df_feature_importances_i, on='feature', suffixes=('', idx + 1))\n",
    "            \n",
    "    df_valid_pred = df_valid_pred.sort_values(by=['TransactionID'])\n",
    "    df_valid_pred = df_valid_pred.reset_index(drop=True)\n",
    "\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred = df_test_pred.sort_values(by=['TransactionID'])\n",
    "        df_test_pred = df_test_pred.reset_index(drop=True)\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('-' * 30)\n",
    "        print('Training has finished.')\n",
    "        print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "        print('Mean AUC:', his.val_auc.mean(), his.trn_auc.mean())\n",
    "        print('-' * 30)\n",
    "    return his, df_feature_importances, df_valid_pred, df_test_pred, his.val_auc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folds = TimeSeriesSplit(n_splits=5)\n",
    "# folds = GroupKFold(n_splits=5)\n",
    "folds = KFold(n_splits=8, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 516722 samples, validate on 73818 samples\n",
      "Epoch 1/200\n",
      "516722/516722 [==============================] - 75s 145us/step - loss: 0.1235 - auc: 0.7883 - val_loss: 0.1212 - val_auc: 0.8150\n",
      "Epoch 2/200\n",
      "516722/516722 [==============================] - 74s 143us/step - loss: 0.1126 - auc: 0.8210 - val_loss: 0.1293 - val_auc: 0.8280\n",
      "Epoch 3/200\n",
      "516722/516722 [==============================] - 78s 151us/step - loss: 0.1104 - auc: 0.8320 - val_loss: 0.1067 - val_auc: 0.8346\n",
      "Epoch 4/200\n",
      "516722/516722 [==============================] - 72s 138us/step - loss: 0.1088 - auc: 0.8366 - val_loss: 0.1320 - val_auc: 0.8384\n",
      "Epoch 5/200\n",
      "516722/516722 [==============================] - 76s 147us/step - loss: 0.1070 - auc: 0.8402 - val_loss: 0.1252 - val_auc: 0.8422\n",
      "Epoch 6/200\n",
      "516722/516722 [==============================] - 79s 153us/step - loss: 0.1059 - auc: 0.8438 - val_loss: 0.1444 - val_auc: 0.8452\n",
      "Epoch 7/200\n",
      "516722/516722 [==============================] - 75s 146us/step - loss: 0.1048 - auc: 0.8465 - val_loss: 0.1830 - val_auc: 0.8478\n",
      "Epoch 8/200\n",
      "516722/516722 [==============================] - 75s 144us/step - loss: 0.1036 - auc: 0.8490 - val_loss: 0.1708 - val_auc: 0.8501\n",
      "Epoch 9/200\n",
      "516722/516722 [==============================] - 77s 150us/step - loss: 0.1031 - auc: 0.8512 - val_loss: 0.1431 - val_auc: 0.8520\n",
      "Epoch 10/200\n",
      "516722/516722 [==============================] - 74s 143us/step - loss: 0.1026 - auc: 0.8528 - val_loss: 0.2782 - val_auc: 0.8537\n",
      "Epoch 11/200\n",
      "516722/516722 [==============================] - 74s 143us/step - loss: 0.1016 - auc: 0.8546 - val_loss: 0.1947 - val_auc: 0.8551\n",
      "Epoch 12/200\n",
      "516722/516722 [==============================] - 70s 136us/step - loss: 0.1007 - auc: 0.8557 - val_loss: 0.1747 - val_auc: 0.8564\n",
      "Epoch 13/200\n",
      "516722/516722 [==============================] - 73s 142us/step - loss: 0.0993 - auc: 0.8572 - val_loss: 0.2243 - val_auc: 0.8579\n",
      "Epoch 14/200\n",
      "516722/516722 [==============================] - 76s 148us/step - loss: 0.0977 - auc: 0.8586 - val_loss: 0.1900 - val_auc: 0.8594\n",
      "Epoch 15/200\n",
      "516722/516722 [==============================] - 73s 141us/step - loss: 0.0967 - auc: 0.8603 - val_loss: 0.1737 - val_auc: 0.8610\n",
      "Epoch 16/200\n",
      "516722/516722 [==============================] - 72s 140us/step - loss: 0.0960 - auc: 0.8617 - val_loss: 0.1902 - val_auc: 0.8624\n",
      "Epoch 17/200\n",
      "516722/516722 [==============================] - 73s 141us/step - loss: 0.0951 - auc: 0.8631 - val_loss: 0.2838 - val_auc: 0.8638\n",
      "Epoch 18/200\n",
      "516722/516722 [==============================] - 74s 142us/step - loss: 0.0942 - auc: 0.8645 - val_loss: 0.2089 - val_auc: 0.8652\n",
      "Epoch 19/200\n",
      "516722/516722 [==============================] - 76s 146us/step - loss: 0.0926 - auc: 0.8660 - val_loss: 0.2640 - val_auc: 0.8667\n",
      "Epoch 20/200\n",
      "516722/516722 [==============================] - 84s 164us/step - loss: 0.0916 - auc: 0.8674 - val_loss: 0.2006 - val_auc: 0.8680\n",
      "Epoch 21/200\n",
      "516722/516722 [==============================] - 75s 146us/step - loss: 0.0915 - auc: 0.8686 - val_loss: 0.2180 - val_auc: 0.8693\n",
      "Epoch 22/200\n",
      "516722/516722 [==============================] - 72s 139us/step - loss: 0.0901 - auc: 0.8700 - val_loss: 0.2814 - val_auc: 0.8706\n",
      "Epoch 23/200\n",
      "516608/516722 [============================>.] - ETA: 0s - loss: 0.0892 - auc: 0.8712"
     ]
    }
   ],
   "source": [
    "his, df_feature_importances, df_valid_pred, df_test_pred, val_metric = process(folds, df_train,df_test, columns, is_output_feature_importance=0, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
