{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(action=\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(action=\"ignore\",category=FutureWarning)\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split, GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold,TimeSeriesSplit, GroupKFold\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers import BatchNormalization,Add,Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras import callbacks\n",
    "from keras import backend as K\n",
    "\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/IEEE-CIS-Fraud-Detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f'{folder_path}/df_train2.gzde', compression='gzip')#.iloc[:10000,:]\n",
    "df_test = pd.read_pickle(f'{folder_path}/df_test2.gzde', compression='gzip')#.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_train.columns.tolist()\n",
    "columns.remove('TransactionID')\n",
    "columns.remove('TransactionDT')\n",
    "columns.remove('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "from tensorflow.python.framework import graph_util\n",
    "import os\n",
    "\n",
    "class VariationalAE(object):\n",
    "\n",
    "    \"\"\" Variation Autoencoder (VAE) with an sklearn-like interface implemented using TensorFlow.\n",
    "\n",
    "    This implementation uses probabilistic encoders and decoders using Gaussian\n",
    "    distributions and  realized by multi-layer perceptrons. The VAE can be learned\n",
    "    end-to-end.\n",
    "\n",
    "    See \"Auto-Encoding Variational Bayes\" by Kingma and Welling for more details.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_dim, latent_dim, encoder_hidden_layer_sizes, decoder_hidden_layer_sizes, \n",
    "                 hidden_layer_activation_function, output_activation_function, kl_coef, drop_out, learning_rate, \n",
    "                 batch_size, epochs, random_state=0, **kwargs):\n",
    "        \n",
    "        \n",
    "        self.X_dim = X_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder_hidden_layer_sizes = encoder_hidden_layer_sizes\n",
    "        self.decoder_hidden_layer_sizes = decoder_hidden_layer_sizes\n",
    "        \n",
    "        if hidden_layer_activation_function == 'relu' or hidden_layer_activation_function == 'RELU':\n",
    "            self.hidden_layer_activation_function = tf.nn.relu\n",
    "        elif hidden_layer_activation_function == 'sigmoid' or hidden_layer_activation_function == 'SIGMOID':\n",
    "            self.hidden_layer_activation_function = tf.nn.sigmoid\n",
    "        elif hidden_layer_activation_function == 'tanh' or hidden_layer_activation_function == 'TANH':\n",
    "            self.hidden_layer_activation_function = tf.nn.tanh\n",
    "        else:\n",
    "            raise Exception('unknow activation function name')\n",
    "        \n",
    "            \n",
    "        if output_activation_function == 'relu' or output_activation_function == 'RELU':\n",
    "            self.output_activation_function = tf.nn.relu\n",
    "        elif output_activation_function == 'sigmoid' or output_activation_function == 'SIGMOID':\n",
    "            self.output_activation_function = tf.nn.sigmoid\n",
    "        elif output_activation_function == 'tanh' or output_activation_function == 'TANH':\n",
    "            self.output_activation_function = tf.nn.tanh\n",
    "        elif output_activation_function == 'softplus' or output_activation_function == 'SOFTPLUS':\n",
    "            self.output_activation_function = tf.nn.softplus\n",
    "        elif output_activation_function == 'softmax' or output_activation_function == 'SOFTMAX':\n",
    "            self.output_activation_function = tf.nn.softmax\n",
    "        else:\n",
    "            raise Exception('unknow activation function name')\n",
    "            \n",
    "        self.kl_coef = kl_coef\n",
    "        self.drop_out = drop_out\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.random_state = random_state\n",
    "        self.is_training = False\n",
    "        \n",
    "        tf.set_random_seed(random_state)\n",
    "        tf.reset_default_graph()\n",
    "        self.build_graph()\n",
    "        self.compile_graph()\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.sess.run([tf.local_variables_initializer(), tf.global_variables_initializer(),])\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def fit(self, X, X_val=None, **kwargs):\n",
    "        \n",
    "        his = []\n",
    "        # Training\n",
    "        n_sample = X.shape[0]\n",
    "        n_steps = int(self.epochs*n_sample/self.batch_size)\n",
    "        # input_queue = tf.train.slice_input_producer([X], shuffle=False, num_epochs=self.epochs)\n",
    "        batch_X = tf.train.batch([X], batch_size=self.batch_size, enqueue_many=True)\n",
    "\n",
    "        # self.sess.run([\n",
    "        #     tf.local_variables_initializer(),\n",
    "        #     tf.global_variables_initializer(),\n",
    "        # ])\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=self.sess, coord=coord)\n",
    "\n",
    "        try:\n",
    "            # in most cases coord.should_stop() will return True\n",
    "            # when there are no more samples to read\n",
    "            # if num_epochs=0 then it will run for ever\n",
    "            index = 1\n",
    "            while not coord.should_stop():\n",
    "                # will start reading, working data from input queue\n",
    "                # and \"fetch\" the results of the computation graph\n",
    "                # into raw_images and raw_labels\n",
    "                batch_x = self.sess.run(batch_X)\n",
    "                self.is_training = True\n",
    "                self.sess.run((self.train_op), feed_dict={self.x: batch_x, self.keep_prob: 1 - self.drop_out})\n",
    "                if (index % int(n_sample / self.batch_size) == 0):\n",
    "                    d_ = {}\n",
    "                    self.is_training = False\n",
    "                    mse, loss, kle, reconstructione = self.sess.run((self.mse, self.loss, self.kle, self.reconstructione),feed_dict={self.x: X, self.keep_prob: 1.0})\n",
    "                    d_ = {'loss': loss,'kle': kle, 'reconstructione': reconstructione, 'mse': mse}\n",
    "                    if type(X_val)!=type(None):\n",
    "                        val_mse, val_loss, val_kle, val_reconstructione = self.sess.run((self.mse, self.loss, self.kle, self.reconstructione),feed_dict={self.x: X_val, self.keep_prob: 1.0})\n",
    "                        d_ = {'val_loss': val_loss,'val_kle': val_kle, 'val_reconstructione': val_reconstructione, 'val_mse': val_mse, **d_}\n",
    "                    his.append(d_)    \n",
    "                    \n",
    "                index = index + 1\n",
    "                if index == n_steps+1:\n",
    "                    coord.request_stop()\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "\n",
    "        return his\n",
    "\n",
    "    def scores(self, X, **kwargs):\n",
    "        his = []\n",
    "        for _x in X:\n",
    "            self.is_training = False\n",
    "            mse, loss, kle, reconstructione = self.sess.run(\n",
    "                (self.mse, self.loss, self.kle, self.reconstructione),\n",
    "                feed_dict={self.x: [_x], self.keep_prob: 1.0})\n",
    "            # print('epoch loss', loss)\n",
    "            his.append(\n",
    "                {'loss': loss,\n",
    "                 'kle': kle,\n",
    "                 'reconstructione': reconstructione,\n",
    "                 'mse': mse})\n",
    "        return his\n",
    "    \n",
    "        # latent\n",
    "    def transform(self, X):\n",
    "        latent_list = []\n",
    "        for _x in X:\n",
    "            latent_list.append(self.z.eval(session=self.sess, feed_dict={self.x: [_x], self.keep_prob: 1.0}))\n",
    "        latent_array = np.array(latent_list)\n",
    "        return latent_array\n",
    "\n",
    "    # out put\n",
    "    def predict(self, X):\n",
    "        output_list = []\n",
    "        for _x in X:\n",
    "            output_list.append(self.y.eval(session=self.sess, feed_dict={self.x: [_x], self.keep_prob: 1.0}))\n",
    "        output_array = np.array(output_list)\n",
    "        return output_array\n",
    "\n",
    "    # Gaussian MLP as encoder\n",
    "    def _build_encoder(self):\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        x_ = self.x\n",
    "        input_dim = self.X_dim\n",
    "        for index, unit in enumerate(self.encoder_hidden_layer_sizes):\n",
    "            # 1st hidden layer\n",
    "            w_variable_name_ = 'encoder_w{:d}'.format(index)\n",
    "            b_variable_name_ = 'encoder_b{:d}'.format(index)\n",
    "            w = tf.get_variable(w_variable_name_, [input_dim, unit], initializer=w_init)\n",
    "            b = tf.get_variable(b_variable_name_, [unit], initializer=b_init)\n",
    "            x_ = tf.matmul(x_, w) + b\n",
    "            x_ = tf.layers.batch_normalization(x_, training=self.is_training)\n",
    "            x_ = self.hidden_layer_activation_function(x_)\n",
    "            x_ = tf.nn.dropout(x_, self.keep_prob)\n",
    "            input_dim = unit\n",
    "\n",
    "        # output layer\n",
    "        wo = tf.get_variable('encoder_wo',[unit, self.latent_dim * 2], initializer=w_init)\n",
    "        bo = tf.get_variable('encoder_bo',[self.latent_dim * 2], initializer=b_init)\n",
    "        gaussian_params = tf.matmul(x_, wo) + bo\n",
    "        gaussian_params = tf.layers.batch_normalization(gaussian_params, training=self.is_training)\n",
    "\n",
    "        # The mean parameter is unconstrained\n",
    "        self.mu = gaussian_params[:, :self.latent_dim]\n",
    "        # The standard deviation must be positive. Parametrize with a softplus and\n",
    "        # add a small epsilon for numerical stability\n",
    "        self.sigma = 1e-6 + tf.nn.softplus(gaussian_params[:, self.latent_dim:])\n",
    "\n",
    "        # sampling by re-parameterization technique\n",
    "        eps = tf.random_normal(tf.shape(self.mu), mean=0, stddev=1)\n",
    "        self.z = self.mu + self.sigma * eps\n",
    "\n",
    "\n",
    "    # Bernoulli MLP as decoder\n",
    "    def _build_decoder(self):\n",
    "\n",
    "        # initializers\n",
    "        w_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "        b_init = tf.constant_initializer(0.)\n",
    "\n",
    "        x_ = self.z\n",
    "        input_dim = self.latent_dim\n",
    "        for index, unit in enumerate(self.decoder_hidden_layer_sizes):\n",
    "            # 1st hidden layer\n",
    "            w_variable_name_ = 'decoder_w{:d}'.format(index)\n",
    "            b_variable_name_ = 'decoder_b{:d}'.format(index)\n",
    "            w = tf.get_variable(w_variable_name_, [input_dim, unit], initializer=w_init)\n",
    "            b = tf.get_variable(b_variable_name_, [unit], initializer=b_init)\n",
    "            x_ = tf.matmul(x_, w) + b\n",
    "            x_ = tf.layers.batch_normalization(x_, training=self.is_training)\n",
    "            x_ = self.hidden_layer_activation_function(x_)\n",
    "            x_ = tf.nn.dropout(x_, self.keep_prob)\n",
    "            input_dim = unit\n",
    "\n",
    "        # output layer-mean\n",
    "        wo = tf.get_variable('decoder_wo',[unit, self.X_dim], initializer=w_init)\n",
    "        bo = tf.get_variable('decoder_bo',[self.X_dim], initializer=b_init)\n",
    "        params = tf.matmul(x_, wo) + bo\n",
    "        params = tf.layers.batch_normalization(params, training=self.is_training)\n",
    "        self.y = self.output_activation_function(params, name='output')\n",
    "\n",
    "        return\n",
    "\n",
    "    def _loss(self):\n",
    "\n",
    "        local_epsilon = 1e-6\n",
    "        # marginal_likelihood = self.x * tf.log(tf.clip_by_value(self.y, local_epsilon, 1.0)) + \\\n",
    "        #                             (1 - self.x) * tf.log(tf.clip_by_value(1 - self.y, local_epsilon, 1.0))\n",
    "        y_ = tf.clip_by_value(self.y, local_epsilon, 1 - local_epsilon)\n",
    "        x_ = tf.clip_by_value(self.x, local_epsilon, 1 - local_epsilon)\n",
    "        marginal_likelihood = x_ * tf.log(y_) + (1 - x_) * tf.log(1 - y_)\n",
    "        marginal_likelihood = -1 * tf.reduce_sum(marginal_likelihood, 1)\n",
    "\n",
    "        mu_ = tf.clip_by_value(self.mu, local_epsilon, 1 - local_epsilon)\n",
    "        sigma_ = tf.clip_by_value(self.sigma, local_epsilon, 1 - local_epsilon)\n",
    "        kl_divergence = 1 + tf.log(tf.square(sigma_)) - tf.square(mu_) - tf.square(sigma_)\n",
    "        kl_divergence = -self.kl_coef * tf.reduce_sum(kl_divergence, 1)\n",
    "\n",
    "        self.loss = tf.reduce_mean(marginal_likelihood + kl_divergence, name='loss')\n",
    "        self.mse = tf.sqrt(tf.losses.mean_squared_error(self.y, self.x), name='mse')\n",
    "        self.kle = tf.reduce_mean(kl_divergence, name='kle')\n",
    "        self.reconstructione = tf.reduce_mean(marginal_likelihood, name='reconstructione')\n",
    "        return\n",
    "\n",
    "\n",
    "    def compile_graph(self):\n",
    "        \n",
    "        # loss\n",
    "        self._loss()\n",
    "        # train\n",
    "        self.train_op = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "        return\n",
    "\n",
    "    def build_graph(self):\n",
    "\n",
    "        self.keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.X_dim], name='input')\n",
    "        # encoding\n",
    "        self._build_encoder()\n",
    "        # decoding\n",
    "        self._build_decoder()\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(folds, df_train,df_test, columns, verbose=0):\n",
    "\n",
    "#     aucs = list()\n",
    "    his = []\n",
    "    training_start_time = time()\n",
    "    df_valid_pred = pd.DataFrame()\n",
    "    df_test_pred = pd.DataFrame()\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred['TransactionID'] = df_test['TransactionID'].values\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train[columns].values)\n",
    "        \n",
    "    for fold, (trn_idx, test_idx) in enumerate(folds.split(df_train)):\n",
    "        start_time = time()\n",
    "        if verbose > 1:\n",
    "            print('Training on fold {}'.format(fold + 1))\n",
    "        \n",
    "        vae = VariationalAE(**params)\n",
    "        train_his = vae.fit(scaler.transform(df_train.iloc[trn_idx][df_train['isFraud']==0][columns].values))\n",
    "        scores = vae.scores(scaler.transform(df_train.iloc[test_idx][columns].values))\n",
    "        \n",
    "        df_valid_pred_i = pd.DataFrame(scores)\n",
    "        df_valid_pred_i['TransactionID'] = df_train['TransactionID'].values[test_idx]\n",
    "        df_valid_pred = pd.concat([df_valid_pred, df_valid_pred_i], axis=0)\n",
    "        \n",
    "        y_test_pred = None\n",
    "        if type(df_test)!=type(None):\n",
    "            scores = vae.scores(scaler.transform(df_test[columns].values))\n",
    "            df_test_pred_i = pd.DataFrame(scores)\n",
    "            df_test_pred = pd.concat([df_test_pred, df_test_pred_i], axis=1)\n",
    "        \n",
    "        \n",
    "#         aucs.append(clf.best_score['valid_1']['auc'])\n",
    "        his.append({'train_his':train_his, 'df_valid_pred_i':df_valid_pred_i, 'test_idx':test_idx})\n",
    "        if verbose > 0:\n",
    "            print('Fold {} finished in {}'.format(fold + 1, str(datetime.timedelta(seconds=time() - start_time))))\n",
    "    his = pd.DataFrame(his)\n",
    "            \n",
    "    df_valid_pred = df_valid_pred.sort_values(by=['TransactionID'])\n",
    "    df_valid_pred = df_valid_pred.reset_index(drop=True)\n",
    "\n",
    "    if type(df_test) != type(None):\n",
    "        df_test_pred = df_test_pred.sort_values(by=['TransactionID'])\n",
    "        df_test_pred = df_test_pred.reset_index(drop=True)\n",
    "        \n",
    "        df_test_pred_mean = pd.DataFrame()\n",
    "        df_test_pred_mean['TransactionID'] = df_test_pred['TransactionID'].values\n",
    "        df_test_pred_mean['loss'] = df_test_pred['loss'].mean(axis=1).values\n",
    "        df_test_pred_mean['kle'] = df_test_pred['kle'].mean(axis=1).values\n",
    "        df_test_pred_mean['reconstructione'] = df_test_pred['reconstructione'].mean(axis=1).values\n",
    "        df_test_pred_mean['mse'] = df_test_pred['mse'].mean(axis=1).values\n",
    "    \n",
    "    if verbose > 0:\n",
    "        print('-' * 30)\n",
    "        print('Training has finished.')\n",
    "        print('Total training time is {}'.format(str(datetime.timedelta(seconds=time() - training_start_time))))\n",
    "        print('-' * 30)\n",
    "    return his, df_valid_pred, df_test_pred_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train2 = pd.read_pickle(f'{folder_path}/df_train2.gzde', compression='gzip').iloc[10000:20000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_columns = ['PCA_C_1',\n",
    " 'C1_fq_enc',\n",
    " 'C13',\n",
    " 'PCA_C_2',\n",
    " 'C1',\n",
    " 'C14',\n",
    " 'D2',\n",
    " 'V70',\n",
    " 'M4_target_mean',\n",
    " 'uid3_TransactionAmt_mean',\n",
    " 'addr1_fq_enc',\n",
    " 'card2_TransactionAmt_mean',\n",
    " 'addr1__card1',\n",
    " 'V258',\n",
    " 'M5',\n",
    " 'uid3_TransactionAmt_std',\n",
    " 'uid3_fq_enc',\n",
    " 'D15_to_std_addr1',\n",
    " 'D15_to_mean_addr1',\n",
    " 'C11_fq_enc',\n",
    " 'card1',\n",
    " 'C11',\n",
    " 'card1_TransactionAmt_mean',\n",
    " 'D2_fq_enc',\n",
    " 'uid2_TransactionAmt_mean',\n",
    " 'P_emaildomain__C2',\n",
    " 'M6',\n",
    " 'card2_fq_enc',\n",
    " 'D1',\n",
    " 'C13_fq_enc',\n",
    " 'V317',\n",
    " 'C2',\n",
    " 'TransactionAmt',\n",
    " 'addr1',\n",
    " 'uid2_fq_enc',\n",
    " 'V294',\n",
    " 'uid_TransactionAmt_mean',\n",
    " 'C14_fq_enc',\n",
    " 'card1_fq_enc',\n",
    " 'C8',\n",
    " 'TransactionAmt_log1p',\n",
    " 'card1_count_full',\n",
    " 'card3_TransactionAmt_mean',\n",
    " 'Card_ID',\n",
    " 'M4',\n",
    " 'C2_fq_enc',\n",
    " 'P_emaildomain_fq_enc',\n",
    " 'ProductCD_target_mean',\n",
    " 'uid2_TransactionAmt_std',\n",
    " 'uid_fq_enc',\n",
    " 'card5__P_emaildomain',\n",
    " 'card6',\n",
    " 'uid_TransactionAmt_std',\n",
    " 'card1_TransactionAmt_std',\n",
    " 'id_20',\n",
    " 'card2_count_full',\n",
    " 'C6_fq_enc',\n",
    " 'card2_TransactionAmt_std',\n",
    " 'V87',\n",
    " 'card2__dist1',\n",
    " 'card2',\n",
    " 'C6',\n",
    " 'R_emaildomain',\n",
    " 'PCA_C_0',\n",
    " 'C5',\n",
    " 'TransactionAmt_Log',\n",
    " 'TransactionAmt_decimal',\n",
    " 'D15_to_std_card1',\n",
    " 'D3',\n",
    " 'PCA_V_28',\n",
    " 'uid',\n",
    " 'V91',\n",
    " 'V45',\n",
    " 'uid3',\n",
    " 'card5_TransactionAmt_mean',\n",
    " 'card2__id_20',\n",
    " 'D3_fq_enc',\n",
    " 'V69',\n",
    " 'card6_count_full',\n",
    " 'C5_fq_enc',\n",
    " 'V283',\n",
    " 'uid2',\n",
    " 'V257',\n",
    " 'DeviceInfo_version',\n",
    " 'TransactionAmt_to_mean_card1',\n",
    " 'C12',\n",
    " 'card1__card5',\n",
    " 'V189',\n",
    " 'P_emaildomain',\n",
    " 'D1_fq_enc',\n",
    " 'D15_to_mean_card1',\n",
    " 'TransactionAmt_to_mean_card_id',\n",
    " 'card3_TransactionAmt_std',\n",
    " 'R_emaildomain_prefix',\n",
    " 'C8_fq_enc',\n",
    " 'ProductCD',\n",
    " 'P_emaildomain_prefix',\n",
    " 'id_19',\n",
    " 'V310',\n",
    " 'id_17',\n",
    " 'M3',\n",
    " 'C10',\n",
    " 'V245',\n",
    " 'V62',\n",
    " 'id_31_device',\n",
    " 'V187',\n",
    " 'card3',\n",
    " 'DeviceInfo_device_fq_enc',\n",
    " 'D14',\n",
    " 'V243',\n",
    " 'V53',\n",
    " 'V90',\n",
    " 'V67',\n",
    " 'C9_fq_enc',\n",
    " '_Days',\n",
    " 'email_check',\n",
    " 'V312',\n",
    " 'mean_last',\n",
    " 'V313',\n",
    " 'C9',\n",
    " 'id_05',\n",
    " 'id_09',\n",
    " 'V156',\n",
    " 'P_emaildomain_1',\n",
    " 'V54',\n",
    " 'V133',\n",
    " 'DeviceType',\n",
    " 'V308',\n",
    " 'C12_fq_enc',\n",
    " 'V30',\n",
    " 'V261',\n",
    " 'P_emaildomain_2',\n",
    " 'V274',\n",
    " 'card5_fq_enc',\n",
    " 'V307',\n",
    " 'V83',\n",
    " 'V149',\n",
    " 'V61',\n",
    " 'V201',\n",
    " 'id_30_device',\n",
    " 'V102',\n",
    " 'card5',\n",
    " 'id_02_to_std_addr1',\n",
    " 'id_30_fq_enc',\n",
    " 'V82',\n",
    " 'V13',\n",
    " 'D8_fq_enc',\n",
    " 'first_value_addr1',\n",
    " 'DT_day',\n",
    " 'V86',\n",
    " 'DeviceInfo__P_emaildomain',\n",
    " 'V320',\n",
    " 'V76',\n",
    " 'D5',\n",
    " 'V35',\n",
    " 'max_last',\n",
    " 'addr2',\n",
    " 'V188',\n",
    " 'V264',\n",
    " 'V259',\n",
    " 'C10_fq_enc',\n",
    " 'TransactionAmt_to_std_card_id',\n",
    " 'PCA_D_1',\n",
    " 'V75',\n",
    " 'V315',\n",
    " 'C4_fq_enc',\n",
    " 'device_version',\n",
    " 'DeviceInfo_version_fq_enc',\n",
    " 'V56',\n",
    " 'id_38',\n",
    " 'V281',\n",
    " 'first_value_card1',\n",
    " 'id_31_device_fq_enc',\n",
    " 'V55',\n",
    " 'V44',\n",
    " 'DT_hour',\n",
    " 'M9',\n",
    " 'card4_count_full',\n",
    " 'min_last',\n",
    " 'DeviceInfo_device',\n",
    " 'id_18',\n",
    " 'C4',\n",
    " 'V12',\n",
    " 'dist1_fq_enc',\n",
    " 'card5_TransactionAmt_std',\n",
    " '_Second',\n",
    " 'M_sum',\n",
    " 'id_37',\n",
    " 'V29',\n",
    " 'DeviceInfo_fq_enc',\n",
    " 'D11',\n",
    " 'V262',\n",
    " 'V198',\n",
    " 'V314',\n",
    " 'V256',\n",
    " 'id_02_to_mean_addr1',\n",
    " 'V38',\n",
    " 'R_emaildomain_2',\n",
    " '_Hours',\n",
    " 'V66',\n",
    " 'D8',\n",
    " 'V296',\n",
    " 'V279',\n",
    " 'V78',\n",
    " 'D5_fq_enc',\n",
    " 'V147',\n",
    " 'V306',\n",
    " 'V20',\n",
    " '_Minutes',\n",
    " 'V49',\n",
    " 'V48',\n",
    " 'id_30_version_fq_enc',\n",
    " 'V275',\n",
    " 'V335',\n",
    " 'V280',\n",
    " 'V127',\n",
    " 'V36',\n",
    " 'R_emaildomain_1',\n",
    " 'V19',\n",
    " 'card5_count_full',\n",
    " 'id_28',\n",
    " 'screen_height',\n",
    " 'id_14',\n",
    " 'id_33',\n",
    " 'V23',\n",
    " 'V244',\n",
    " 'V287',\n",
    " 'PCA_D_2',\n",
    " 'id_02__id_20',\n",
    " 'V326',\n",
    " 'id_33_fq_enc',\n",
    " 'id_32',\n",
    " 'addr2_fq_enc',\n",
    " 'V24',\n",
    " 'id_30',\n",
    " 'dist1',\n",
    " 'V277',\n",
    " 'C7',\n",
    " 'V152',\n",
    " 'V232',\n",
    " 'M7',\n",
    " 'std_last',\n",
    " 'V282',\n",
    " 'device_name',\n",
    " 'V199',\n",
    " 'card4',\n",
    " 'V131',\n",
    " 'V99',\n",
    " 'V324',\n",
    " 'V139',\n",
    " 'id_02__D8',\n",
    " 'V253',\n",
    " 'id_33_1',\n",
    " 'id_02',\n",
    " 'PCA_D_0',\n",
    " 'V319',\n",
    " 'V160',\n",
    " 'V155',\n",
    " 'V336',\n",
    " 'M1',\n",
    " 'V251',\n",
    " 'V50',\n",
    " 'V108',\n",
    " 'M_na',\n",
    " 'screen_width',\n",
    " 'V125',\n",
    " 'V57',\n",
    " 'id_03',\n",
    " 'V239',\n",
    " 'V115',\n",
    " 'V123',\n",
    " 'count_cluster',\n",
    " 'V109',\n",
    " 'V298',\n",
    " 'V231',\n",
    " 'PCA_D_6',\n",
    " 'V291',\n",
    " 'V215',\n",
    " 'V148',\n",
    " 'V124',\n",
    " 'V293',\n",
    " 'card3_count_full',\n",
    " 'Transaction_hour',\n",
    " 'V162',\n",
    " 'version_id_30',\n",
    " 'V304',\n",
    " 'V16',\n",
    " 'V309',\n",
    " 'V134',\n",
    " 'V273',\n",
    " 'V105',\n",
    " 'V219',\n",
    " 'C3_fq_enc',\n",
    " 'V31',\n",
    " 'V272',\n",
    " 'V289',\n",
    " 'V58',\n",
    " 'V217',\n",
    " 'V255',\n",
    " 'V271',\n",
    " 'V216',\n",
    " 'V327',\n",
    " 'V126',\n",
    " 'V128',\n",
    " 'V165',\n",
    " 'card3_fq_enc',\n",
    " 'V197',\n",
    " 'V132',\n",
    " 'id_30_version',\n",
    " 'V34',\n",
    " 'V143',\n",
    " 'id_34',\n",
    " 'V332',\n",
    " 'V323',\n",
    " 'V25',\n",
    " 'V161',\n",
    " 'V200',\n",
    " 'V210',\n",
    " 'V5',\n",
    " 'V318',\n",
    " 'browser_id_31',\n",
    " 'id_29',\n",
    " 'V11',\n",
    " 'V248',\n",
    " 'V242',\n",
    " 'OS_id_30',\n",
    " 'V237',\n",
    " 'C3',\n",
    " 'V65',\n",
    " 'DeviceInfo',\n",
    " 'V292',\n",
    " 'V15',\n",
    " 'V229',\n",
    " 'V183',\n",
    " 'V190',\n",
    " 'V302',\n",
    " 'V7',\n",
    " 'PCA_D_5',\n",
    " 'V96',\n",
    " 'V101',\n",
    " 'V135',\n",
    " 'V301',\n",
    " 'V9',\n",
    " 'V158',\n",
    " 'V153',\n",
    " 'V46',\n",
    " 'V14',\n",
    " 'V193',\n",
    " 'V116',\n",
    " 'V252',\n",
    " 'id_02_to_mean_card1',\n",
    " 'id_30_device_fq_enc',\n",
    " 'PCA_D_7',\n",
    " 'V112',\n",
    " 'V94',\n",
    " 'V316',\n",
    " 'V150',\n",
    " 'V311',\n",
    " 'D7',\n",
    " 'V159',\n",
    " 'V8',\n",
    " 'V180',\n",
    " 'V142',\n",
    " 'V321',\n",
    " 'V195',\n",
    " 'V325',\n",
    " '_Weekdays',\n",
    " 'make_day_feature',\n",
    " 'V186',\n",
    " 'V227',\n",
    " 'id_25',\n",
    " 'V100',\n",
    " 'V1',\n",
    " 'V3',\n",
    " 'V6',\n",
    " 'V322',\n",
    " 'V331',\n",
    " 'V303',\n",
    " 'V221',\n",
    " 'V26',\n",
    " 'V2',\n",
    " 'V74',\n",
    " 'V172',\n",
    " 'V286',\n",
    " 'V130',\n",
    " 'V10',\n",
    " 'V334',\n",
    " 'V207',\n",
    " 'V122',\n",
    " 'V299',\n",
    " 'V157',\n",
    " 'V337',\n",
    " 'V226',\n",
    " 'V167',\n",
    " 'V154',\n",
    " 'V95',\n",
    " 'V79',\n",
    " 'V290',\n",
    " 'id_33_0',\n",
    " 'M2',\n",
    " 'clusters_D',\n",
    " 'V51',\n",
    " 'V284',\n",
    " 'V151',\n",
    " 'V98',\n",
    " 'V297',\n",
    " 'V191',\n",
    " 'V144',\n",
    " 'V119',\n",
    " 'V269',\n",
    " 'V27',\n",
    " 'V141',\n",
    " 'V192',\n",
    " 'V138',\n",
    " 'V120',\n",
    " 'V110',\n",
    " 'clusters_C',\n",
    " 'had_id',\n",
    " 'V111',\n",
    " 'V118',\n",
    " 'V196',\n",
    " 'V113',\n",
    " 'V114',\n",
    " 'V121',\n",
    " 'V28',\n",
    " 'V117',\n",
    " 'V278',\n",
    " 'V249',\n",
    " 'V305',\n",
    " 'V240',\n",
    " 'id_36',\n",
    " 'id_35',\n",
    " 'V241',\n",
    " 'V41',\n",
    " 'V328',\n",
    " 'V247',\n",
    " 'id_27',\n",
    " 'id_23',\n",
    " 'id_22',\n",
    " 'id_08',\n",
    " 'V88',\n",
    " 'V250',\n",
    " 'V107',\n",
    " 'V204',\n",
    " 'V214',\n",
    " 'V136',\n",
    " 'V209',\n",
    " 'V137',\n",
    " 'V330',\n",
    " 'V89',\n",
    " 'V140',\n",
    " 'V145',\n",
    " 'V254',\n",
    " 'id_24',\n",
    " 'V270',\n",
    " 'PCA_D_3',\n",
    " 'Transaction_day_of_week',\n",
    " 'V178',\n",
    " 'V33',\n",
    " 'V104',\n",
    " 'V146',\n",
    " 'V68',\n",
    " 'V163',\n",
    " 'id_36_count_full',\n",
    " 'V73',\n",
    " 'V213',\n",
    " 'V168',\n",
    " 'V236',\n",
    " 'V173',\n",
    " 'V97',\n",
    " 'V106',\n",
    " 'V212',\n",
    " 'V129',\n",
    " 'V263',\n",
    " 'V37',\n",
    " 'V164',\n",
    " 'V230',\n",
    " 'id_26',\n",
    " 'V174',\n",
    " 'M8',\n",
    " 'V166',\n",
    " 'V184',\n",
    " 'V233',\n",
    " 'V175',\n",
    " 'D12',\n",
    " 'V300',\n",
    " 'V235',\n",
    " 'V234',\n",
    " 'V288',\n",
    " 'V205',\n",
    " 'V238',\n",
    " 'V329',\n",
    " 'V246',\n",
    " 'V194',\n",
    " 'V47',\n",
    " 'DT_day_week',\n",
    " 'V218',\n",
    " 'make_hour_feature',\n",
    " 'id_16',\n",
    " 'V211',\n",
    " 'id_15',\n",
    " 'D6',\n",
    " 'V32',\n",
    " 'V222',\n",
    " 'V182',\n",
    " 'V228',\n",
    " 'PCA_D_4',\n",
    " 'V177',\n",
    " 'V339',\n",
    " 'id_21',\n",
    " 'V267',\n",
    " 'V4',\n",
    " 'V185',\n",
    " 'id_07',\n",
    " 'V179',\n",
    " 'D7_fq_enc',\n",
    " 'V338',\n",
    " 'V103',\n",
    " 'V206',\n",
    " 'V265',\n",
    " 'id_02_to_mean_card4',\n",
    " 'V260',\n",
    " 'id_12',\n",
    " 'V333',\n",
    " 'id_10',\n",
    " 'id_02_to_std_card4',\n",
    " 'V181',\n",
    " 'dist2',\n",
    " 'V52',\n",
    " 'dist2_fq_enc',\n",
    " 'C7_fq_enc',\n",
    " 'V202',\n",
    " 'V276',\n",
    " 'V77',\n",
    " 'V208',\n",
    " 'D9',\n",
    " 'V176',\n",
    " 'V171',\n",
    " 'V224',\n",
    " 'id_11',\n",
    " 'D13',\n",
    " 'id_04',\n",
    " 'V203',\n",
    " 'V225',\n",
    " 'V170',\n",
    " 'TransactionAmt_check',\n",
    " 'V295',\n",
    " 'V220',\n",
    " 'V169',\n",
    " 'R_emaildomain_fq_enc',\n",
    " 'V268',\n",
    " 'D6_fq_enc',\n",
    " 'id_06',\n",
    " 'V285',\n",
    " 'V266',\n",
    " 'V223',\n",
    " 'id_01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=8, shuffle=False, random_state=42)\n",
    "params = {\n",
    "    'X_dim': len(sorted_columns[:200]),\n",
    "    'latent_dim': 2,\n",
    "    'encoder_hidden_layer_sizes':[1024, 256],\n",
    "    'decoder_hidden_layer_sizes':[64],\n",
    "    'hidden_layer_activation_function':'relu',\n",
    "    'output_activation_function':'sigmoid',\n",
    "    'kl_coef': .5,\n",
    "    'drop_out': 0.1,                \n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 16,\n",
    "    'epochs': 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-c7e40a9cb900>:163: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-c7e40a9cb900>:165: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:667: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-4-c7e40a9cb900>:77: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:753: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/input.py:753: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-4-c7e40a9cb900>:84: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "his, df_valid_pred, df_test_pred = process(folds, df_train,df_test, sorted_columns[:200], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "      <th>TransactionID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>114.867157</td>\n",
       "      <td>0.502394</td>\n",
       "      <td>114.364761</td>\n",
       "      <td>0.152810</td>\n",
       "      <td>2987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99.665977</td>\n",
       "      <td>0.519566</td>\n",
       "      <td>99.146408</td>\n",
       "      <td>0.121638</td>\n",
       "      <td>2987001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>106.663673</td>\n",
       "      <td>0.502882</td>\n",
       "      <td>106.160789</td>\n",
       "      <td>0.100766</td>\n",
       "      <td>2987002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>127.823006</td>\n",
       "      <td>0.658024</td>\n",
       "      <td>127.164978</td>\n",
       "      <td>0.146039</td>\n",
       "      <td>2987003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>166.206467</td>\n",
       "      <td>0.031082</td>\n",
       "      <td>166.175385</td>\n",
       "      <td>0.143271</td>\n",
       "      <td>2987004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>161.074203</td>\n",
       "      <td>0.534761</td>\n",
       "      <td>160.539444</td>\n",
       "      <td>0.134931</td>\n",
       "      <td>2996995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>120.351067</td>\n",
       "      <td>1.159901</td>\n",
       "      <td>119.191162</td>\n",
       "      <td>0.186028</td>\n",
       "      <td>2996996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>108.676117</td>\n",
       "      <td>1.109847</td>\n",
       "      <td>107.566269</td>\n",
       "      <td>0.115891</td>\n",
       "      <td>2996997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>111.611336</td>\n",
       "      <td>0.504733</td>\n",
       "      <td>111.106606</td>\n",
       "      <td>0.135386</td>\n",
       "      <td>2996998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>81.563492</td>\n",
       "      <td>0.015317</td>\n",
       "      <td>81.548172</td>\n",
       "      <td>0.118210</td>\n",
       "      <td>2996999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            loss       kle  reconstructione       mse  TransactionID\n",
       "0     114.867157  0.502394       114.364761  0.152810        2987000\n",
       "1      99.665977  0.519566        99.146408  0.121638        2987001\n",
       "2     106.663673  0.502882       106.160789  0.100766        2987002\n",
       "3     127.823006  0.658024       127.164978  0.146039        2987003\n",
       "4     166.206467  0.031082       166.175385  0.143271        2987004\n",
       "...          ...       ...              ...       ...            ...\n",
       "9995  161.074203  0.534761       160.539444  0.134931        2996995\n",
       "9996  120.351067  1.159901       119.191162  0.186028        2996996\n",
       "9997  108.676117  1.109847       107.566269  0.115891        2996997\n",
       "9998  111.611336  0.504733       111.106606  0.135386        2996998\n",
       "9999   81.563492  0.015317        81.548172  0.118210        2996999\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>loss</th>\n",
       "      <th>kle</th>\n",
       "      <th>reconstructione</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2997000</td>\n",
       "      <td>118.942210</td>\n",
       "      <td>0.770884</td>\n",
       "      <td>118.171326</td>\n",
       "      <td>0.146101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2997001</td>\n",
       "      <td>111.266341</td>\n",
       "      <td>0.517203</td>\n",
       "      <td>110.749136</td>\n",
       "      <td>0.135822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2997002</td>\n",
       "      <td>110.686563</td>\n",
       "      <td>0.491461</td>\n",
       "      <td>110.195102</td>\n",
       "      <td>0.120008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2997003</td>\n",
       "      <td>98.938614</td>\n",
       "      <td>0.362082</td>\n",
       "      <td>98.576534</td>\n",
       "      <td>0.102681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2997004</td>\n",
       "      <td>111.863249</td>\n",
       "      <td>0.955579</td>\n",
       "      <td>110.907671</td>\n",
       "      <td>0.151147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>3006995</td>\n",
       "      <td>198.098608</td>\n",
       "      <td>2.875278</td>\n",
       "      <td>195.223331</td>\n",
       "      <td>0.200928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>3006996</td>\n",
       "      <td>122.023468</td>\n",
       "      <td>0.497102</td>\n",
       "      <td>121.526366</td>\n",
       "      <td>0.203341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>3006997</td>\n",
       "      <td>120.004228</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>119.541174</td>\n",
       "      <td>0.198779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>3006998</td>\n",
       "      <td>128.002359</td>\n",
       "      <td>0.535765</td>\n",
       "      <td>127.466599</td>\n",
       "      <td>0.212015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>3006999</td>\n",
       "      <td>162.257040</td>\n",
       "      <td>0.834633</td>\n",
       "      <td>161.422412</td>\n",
       "      <td>0.187575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TransactionID        loss       kle  reconstructione       mse\n",
       "0           2997000  118.942210  0.770884       118.171326  0.146101\n",
       "1           2997001  111.266341  0.517203       110.749136  0.135822\n",
       "2           2997002  110.686563  0.491461       110.195102  0.120008\n",
       "3           2997003   98.938614  0.362082        98.576534  0.102681\n",
       "4           2997004  111.863249  0.955579       110.907671  0.151147\n",
       "...             ...         ...       ...              ...       ...\n",
       "9995        3006995  198.098608  2.875278       195.223331  0.200928\n",
       "9996        3006996  122.023468  0.497102       121.526366  0.203341\n",
       "9997        3006997  120.004228  0.463054       119.541174  0.198779\n",
       "9998        3006998  128.002359  0.535765       127.466599  0.212015\n",
       "9999        3006999  162.257040  0.834633       161.422412  0.187575\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
